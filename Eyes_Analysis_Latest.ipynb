{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22039175-2e18-4e2d-9abf-e93ef7a43c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Frame Count       FPS  Total Blinks  Total Looked Left  Total Looked Right  \\\n",
      "0       3039.0  17.94185          64.0              113.0                64.0   \n",
      "\n",
      "   Total Looked Center  Percentage Looked Left  Percentage Looked Right  \\\n",
      "0               2861.0                3.718328                 2.105956   \n",
      "\n",
      "   Percentage Looked Center  Percentage Blinks  \n",
      "0                  94.14281           2.105956  \n"
     ]
    }
   ],
   "source": [
    "# FUNCTION BASED WITH VIDEO PATH AS INPUT TO THE MAIN FUNCTION\n",
    "# WITH VIDEO UNREADBILITY ERROR HANDLING\n",
    "\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import utils, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# variables \n",
    "frame_counter =0\n",
    "CEF_COUNTER =0\n",
    "TOTAL_BLINKS =0\n",
    "looked_left_count = 0\n",
    "looked_right_count = 0\n",
    "looked_center_count = 0\n",
    "# constants\n",
    "CLOSED_EYES_FRAME =3\n",
    "FONTS =cv.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "# face bounder indices \n",
    "FACE_OVAL=[ 10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103,67, 109]\n",
    "\n",
    "# lips indices for Landmarks\n",
    "LIPS=[ 61, 146, 91, 181, 84, 17, 314, 405, 321, 375,291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95,185, 40, 39, 37,0 ,267 ,269 ,270 ,409, 415, 310, 311, 312, 13, 82, 81, 42, 183, 78 ]\n",
    "LOWER_LIPS =[61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "UPPER_LIPS=[ 185, 40, 39, 37,0 ,267 ,269 ,270 ,409, 415, 310, 311, 312, 13, 82, 81, 42, 183, 78] \n",
    "# Left eyes indices \n",
    "LEFT_EYE =[ 362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385,384, 398 ]\n",
    "LEFT_EYEBROW =[ 336, 296, 334, 293, 300, 276, 283, 282, 295, 285 ]\n",
    "\n",
    "# right eyes indices\n",
    "RIGHT_EYE=[ 33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161 , 246 ]  \n",
    "RIGHT_EYEBROW=[ 70, 63, 105, 66, 107, 55, 65, 52, 53, 46 ]\n",
    "\n",
    "map_face_mesh = mp.solutions.face_mesh\n",
    "# camera object \n",
    "#camera = cv.VideoCapture(0)\n",
    "#camera = cv.VideoCapture('C:/Users/DIACTO/Videos/Captures/2-3 min introduction video.mp4')\n",
    "\n",
    "# For each individual frames\n",
    "# columns = ['Total Blinks', 'Looked Left Count', 'Looked Right Count']\n",
    "# results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "final_results_columns = ['Frame Count', 'FPS', 'Total Blinks', 'Total Looked Left', 'Total Looked Right', 'Total Looked Center']\n",
    "final_results_df = pd.DataFrame(columns=final_results_columns)\n",
    "\n",
    "# landmark detection function \n",
    "def landmarksDetection(img, results, draw=False):\n",
    "    img_height, img_width= img.shape[:2]\n",
    "    # list[(x,y), (x,y)....]\n",
    "    mesh_coord = [(int(point.x * img_width), int(point.y * img_height)) for point in results.multi_face_landmarks[0].landmark]\n",
    "    if draw :\n",
    "        [cv.circle(img, p, 2, (0,255,0), -1) for p in mesh_coord]\n",
    "\n",
    "    # returning the list of tuples for each landmarks \n",
    "    return mesh_coord\n",
    "\n",
    "# Euclaidean distance \n",
    "def euclaideanDistance(point, point1):\n",
    "    x, y = point\n",
    "    x1, y1 = point1\n",
    "    distance = math.sqrt((x1 - x)**2 + (y1 - y)**2)\n",
    "    return distance\n",
    "\n",
    "# Blinking Ratio\n",
    "def blinkRatio(img, landmarks, right_indices, left_indices):\n",
    "    # Right eyes \n",
    "    # horizontal line \n",
    "    rh_right = landmarks[right_indices[0]]\n",
    "    rh_left = landmarks[right_indices[8]]\n",
    "    # vertical line \n",
    "    rv_top = landmarks[right_indices[12]]\n",
    "    rv_bottom = landmarks[right_indices[4]]\n",
    "    # draw lines on right eyes \n",
    "    # cv.line(img, rh_right, rh_left, utils.GREEN, 2)\n",
    "    # cv.line(img, rv_top, rv_bottom, utils.WHITE, 2)\n",
    "\n",
    "    # LEFT_EYE \n",
    "    # horizontal line \n",
    "    lh_right = landmarks[left_indices[0]]\n",
    "    lh_left = landmarks[left_indices[8]]\n",
    "\n",
    "    # vertical line \n",
    "    lv_top = landmarks[left_indices[12]]\n",
    "    lv_bottom = landmarks[left_indices[4]]\n",
    "\n",
    "    rhDistance = euclaideanDistance(rh_right, rh_left)\n",
    "    rvDistance = euclaideanDistance(rv_top, rv_bottom)\n",
    "\n",
    "    lvDistance = euclaideanDistance(lv_top, lv_bottom)\n",
    "    lhDistance = euclaideanDistance(lh_right, lh_left)\n",
    "\n",
    "    if rvDistance == 0 or lvDistance == 0:\n",
    "        return 0.0\n",
    "    reRatio = rhDistance/rvDistance\n",
    "    leRatio = lhDistance/lvDistance\n",
    "\n",
    "    ratio = (reRatio+leRatio)/2\n",
    "    return ratio \n",
    "\n",
    "# Eyes Extrctor function,\n",
    "def eyesExtractor(img, right_eye_coords, left_eye_coords):\n",
    "    # converting color image to  scale image \n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # getting the dimension of image \n",
    "    dim = gray.shape\n",
    "\n",
    "    # creating mask from gray scale dim\n",
    "    mask = np.zeros(dim, dtype=np.uint8)\n",
    "\n",
    "    # drawing Eyes Shape on mask with white color \n",
    "    cv.fillPoly(mask, [np.array(right_eye_coords, dtype=np.int32)], 255)\n",
    "    cv.fillPoly(mask, [np.array(left_eye_coords, dtype=np.int32)], 255)\n",
    "\n",
    "    # showing the mask \n",
    "    # cv.imshow('mask', mask)\n",
    "    \n",
    "    # draw eyes image on mask, where white shape is \n",
    "    eyes = cv.bitwise_and(gray, gray, mask=mask)\n",
    "    # change black color to gray other than eys \n",
    "    # cv.imshow('eyes draw', eyes)\n",
    "    eyes[mask==0]=155\n",
    "    \n",
    "    # getting minium and maximum x and y  for right and left eyes \n",
    "    # For Right Eye \n",
    "    r_max_x = (max(right_eye_coords, key=lambda item: item[0]))[0]\n",
    "    r_min_x = (min(right_eye_coords, key=lambda item: item[0]))[0]\n",
    "    r_max_y = (max(right_eye_coords, key=lambda item : item[1]))[1]\n",
    "    r_min_y = (min(right_eye_coords, key=lambda item: item[1]))[1]\n",
    "\n",
    "    # For LEFT Eye\n",
    "    l_max_x = (max(left_eye_coords, key=lambda item: item[0]))[0]\n",
    "    l_min_x = (min(left_eye_coords, key=lambda item: item[0]))[0]\n",
    "    l_max_y = (max(left_eye_coords, key=lambda item : item[1]))[1]\n",
    "    l_min_y = (min(left_eye_coords, key=lambda item: item[1]))[1]\n",
    "\n",
    "    # croping the eyes from mask \n",
    "    cropped_right = eyes[r_min_y: r_max_y, r_min_x: r_max_x]\n",
    "    cropped_left = eyes[l_min_y: l_max_y, l_min_x: l_max_x]\n",
    "\n",
    "    # returning the cropped eyes \n",
    "    return cropped_right, cropped_left\n",
    "\n",
    "# Eyes Postion Estimator \n",
    "def positionEstimator(cropped_eye):\n",
    "    # getting height and width of eye \n",
    "    h, w =cropped_eye.shape\n",
    "    \n",
    "    # remove the noise from images\n",
    "    gaussain_blur = cv.GaussianBlur(cropped_eye, (9,9),0)\n",
    "    median_blur = cv.medianBlur(gaussain_blur, 3)\n",
    "\n",
    "    # applying thrsholding to convert binary_image\n",
    "    ret, threshed_eye = cv.threshold(median_blur, 130, 255, cv.THRESH_BINARY)\n",
    "\n",
    "    # create fixd part for eye with \n",
    "    piece = int(w/3) \n",
    "\n",
    "    # slicing the eyes into three parts \n",
    "    right_piece = threshed_eye[0:h, 0:piece]\n",
    "    center_piece = threshed_eye[0:h, piece: piece+piece]\n",
    "    left_piece = threshed_eye[0:h, piece +piece:w]\n",
    "    \n",
    "    # calling pixel counter function\n",
    "    eye_position, color = pixelCounter(right_piece, center_piece, left_piece)\n",
    "\n",
    "    return eye_position, color \n",
    "\n",
    "# creating pixel counter function \n",
    "def pixelCounter(first_piece, second_piece, third_piece):\n",
    "    # counting black pixel in each part \n",
    "    right_part = np.sum(first_piece==0)\n",
    "    center_part = np.sum(second_piece==0)\n",
    "    left_part = np.sum(third_piece==0)\n",
    "    # creating list of these values\n",
    "    eye_parts = [right_part, center_part, left_part]\n",
    "\n",
    "    # getting the index of max values in the list \n",
    "    max_index = eye_parts.index(max(eye_parts))\n",
    "    pos_eye ='' \n",
    "    if max_index==0:\n",
    "        pos_eye=\"RIGHT\"\n",
    "        color=[utils.BLACK, utils.GREEN]\n",
    "    elif max_index==1:\n",
    "        pos_eye = 'CENTER'\n",
    "        color = [utils.YELLOW, utils.PINK]\n",
    "    elif max_index ==2:\n",
    "        pos_eye = 'LEFT'\n",
    "        color = [utils.GRAY, utils.YELLOW]\n",
    "    else:\n",
    "        pos_eye=\"Closed\"\n",
    "        color = [utils.GRAY, utils.YELLOW]\n",
    "    return pos_eye, color\n",
    "\n",
    "def main(video_path):\n",
    "    global frame_counter, CEF_COUNTER, TOTAL_BLINKS, looked_left_count, looked_right_count, looked_center_count\n",
    "    #camera = cv.VideoCapture(video_path)\n",
    "    try:\n",
    "        camera = cv.VideoCapture(video_path)\n",
    "        if not camera.isOpened():\n",
    "            raise FileNotFoundError(f\"Error: Unable to open video file at '{video_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "    with map_face_mesh.FaceMesh(refine_landmarks = True, min_detection_confidence =0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "    \n",
    "        # starting time here \n",
    "        start_time = time.time()\n",
    "        # starting Video loop here.\n",
    "        while True:\n",
    "            frame_counter +=1 # frame counter\n",
    "            ret, frame = camera.read() # getting frame from camera \n",
    "            if not ret: \n",
    "                break # no more frames break\n",
    "            #  resizing frame\n",
    "            \n",
    "            frame = cv.resize(frame, None, fx=1.5, fy=1.5, interpolation=cv.INTER_CUBIC)\n",
    "            frame_height, frame_width= frame.shape[:2]\n",
    "            rgb_frame = cv.cvtColor(frame, cv.COLOR_RGB2BGR)\n",
    "            results  = face_mesh.process(rgb_frame)\n",
    "            if results.multi_face_landmarks:\n",
    "                mesh_coords = landmarksDetection(frame, results, False)\n",
    "                ratio = blinkRatio(frame, mesh_coords, RIGHT_EYE, LEFT_EYE)\n",
    "                # cv.putText(frame, f'ratio {ratio}', (100, 100), FONTS, 1.0, utils.GREEN, 2)\n",
    "                utils.colorBackgroundText(frame,  f'Ratio : {round(ratio,2)}', FONTS, 0.7, (30,100),2, utils.PINK, utils.YELLOW)\n",
    "    \n",
    "                if ratio >5.5:\n",
    "                    CEF_COUNTER +=1\n",
    "                    # cv.putText(frame, 'Blink', (200, 50), FONTS, 1.3, utils.PINK, 2)\n",
    "                    utils.colorBackgroundText(frame,  f'Blink', FONTS, 1.7, (int(frame_height/2), 100), 2, utils.YELLOW, pad_x=6, pad_y=6, )\n",
    "    \n",
    "                else:\n",
    "                    if CEF_COUNTER>CLOSED_EYES_FRAME:\n",
    "                        TOTAL_BLINKS +=1\n",
    "                        CEF_COUNTER =0\n",
    "                # cv.putText(frame, f'Total Blinks: {TOTAL_BLINKS}', (100, 150), FONTS, 0.6, utils.GREEN, 2)\n",
    "                utils.colorBackgroundText(frame,  f'Total Blinks: {TOTAL_BLINKS}', FONTS, 0.7, (30,150),2)\n",
    "                \n",
    "                cv.polylines(frame,  [np.array([mesh_coords[p] for p in LEFT_EYE ], dtype=np.int32)], True, utils.GREEN, 1, cv.LINE_AA)\n",
    "                cv.polylines(frame,  [np.array([mesh_coords[p] for p in RIGHT_EYE ], dtype=np.int32)], True, utils.GREEN, 1, cv.LINE_AA)\n",
    "    \n",
    "                # Blink Detector Counter Completed\n",
    "                right_coords = [mesh_coords[p] for p in RIGHT_EYE]\n",
    "                left_coords = [mesh_coords[p] for p in LEFT_EYE]\n",
    "                crop_right, crop_left = eyesExtractor(frame, right_coords, left_coords)\n",
    "                # cv.imshow('right', crop_right)\n",
    "                # cv.imshow('left', crop_left)\n",
    "                eye_position, color = positionEstimator(crop_right)\n",
    "                utils.colorBackgroundText(frame, f'R: {eye_position}', FONTS, 1.0, (40, 220), 2, color[0], color[1], 8, 8)\n",
    "                eye_position_left, color = positionEstimator(crop_left)\n",
    "                utils.colorBackgroundText(frame, f'L: {eye_position_left}', FONTS, 1.0, (40, 320), 2, color[0], color[1], 8, 8)\n",
    "    \n",
    "                if eye_position == 'LEFT' or eye_position_left == 'LEFT':\n",
    "                    # Increment the count for looking left with both eyes\n",
    "                    looked_left_count += 1\n",
    "                elif eye_position == 'RIGHT' or eye_position_left == 'RIGHT':\n",
    "                    # Increment the count for looking right with both eyes\n",
    "                    looked_right_count += 1\n",
    "                elif eye_position == 'CENTER' or eye_position_left == 'CENTER':\n",
    "                    looked_center_count += 1\n",
    "                \n",
    "    \n",
    "    \n",
    "            # calculating  frame per seconds FPS\n",
    "            end_time = time.time()-start_time\n",
    "            fps = frame_counter/end_time\n",
    "    \n",
    "            frame =utils.textWithBackground(frame,f'FPS: {round(fps,1)}',FONTS, 1.0, (30, 50), bgOpacity=0.9, textThickness=2)\n",
    "            # if frame_counter == 1:\n",
    "            #     final_results_df['FPS'] = fps \n",
    "            average_fps = frame_counter / end_time\n",
    "            final_results_df['FPS'] = average_fps\n",
    "            #results_df.loc[frame_counter] = [TOTAL_BLINKS, looked_left_count, looked_right_count]\n",
    "            #results_df.loc[frame_counter] = [TOTAL_BLINKS, looked_left_count, looked_right_count]\n",
    "            #results_df.loc[frame_counter] = [TOTAL_BLINKS, looked_left_count, looked_right_count]\n",
    "\n",
    "    \n",
    "    \n",
    "            # writing image for thumbnail drawing shape\n",
    "            # cv.imwrite(f'img/frame_{frame_counter}.png', frame)\n",
    "            #cv.imshow('frame', frame)\n",
    "            key = cv.waitKey(2)\n",
    "            if key==ord('q') or key ==ord('Q'):\n",
    "                break\n",
    "    \n",
    "        final_results_df.loc[0] = [frame_counter, average_fps, TOTAL_BLINKS, looked_left_count, looked_right_count, looked_center_count]\n",
    "        #final_results_df.to_csv('final_results.csv', index=False)\n",
    "        total_frames = frame_counter\n",
    "        final_results_df['Percentage Looked Left'] = (final_results_df['Total Looked Left'] / total_frames) * 100\n",
    "        final_results_df['Percentage Looked Right'] = (final_results_df['Total Looked Right'] / total_frames) * 100\n",
    "        final_results_df['Percentage Looked Center'] = (final_results_df['Total Looked Center'] / total_frames) * 100\n",
    "        final_results_df['Percentage Blinks'] = (final_results_df['Total Blinks'] / total_frames) * 100\n",
    "\n",
    "        \n",
    "        #print(final_results_df)\n",
    "        #\n",
    "        #print(results_df)\n",
    "        # cv.destroyAllWindows()\n",
    "        # camera.release()\n",
    "        return (final_results_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     video_path = 'C:/Users/DIACTO/Videos/Captures/2-3 min introduction video.mp4'  # Replace with the desired video file path\n",
    "    video_path = 'C:\\Users\\Vaishnavi\\Downloads\\5442623-hd_1280_720_25fps.mp4'\n",
    "    final_results = main(video_path)\n",
    "\n",
    "    if final_results is not None:\n",
    "        print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "586aae22-9435-4938-8f60-bd46c38e8fc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to parse: node {\n  calculator: \"ImagePropertiesCalculator\"\n  input_stream: \"IMAGE:image\"\n  output_stream: \"SIZE:image_size\"\n}\nnode {\n  calculator: \"PreviousLoopbackCalculator\"\n  input_stream: \"MAIN:image\"\n  input_stream: \"LOOP:face_rects_from_landmarks\"\n  output_stream: \"PREV_LOOP:prev_face_rects_from_landmarks\"\n  input_stream_info {\n    tag_index: \"LOOP\"\n    back_edge: true\n  }\n}\nnode {\n  calculator: \"GateCalculator\"\n  input_stream: \"prev_face_rects_from_landmarks\"\n  output_stream: \"gated_prev_face_rects_from_landmarks\"\n  input_side_packet: \"ALLOW:use_prev_landmarks\"\n  options {\n    [mediapipe.GateCalculatorOptions.ext] {\n      allow: true\n    }\n  }\n}\nnode {\n  calculator: \"NormalizedRectVectorHasMinSizeCalculator\"\n  input_stream: \"ITERABLE:gated_prev_face_rects_from_landmarks\"\n  output_stream: \"prev_has_enough_faces\"\n  input_side_packet: \"num_faces\"\n}\nnode {\n  calculator: \"GateCalculator\"\n  input_stream: \"image\"\n  input_stream: \"DISALLOW:prev_has_enough_faces\"\n  output_stream: \"gated_image\"\n  options {\n    [mediapipe.GateCalculatorOptions.ext] {\n      empty_packets_as_allow: true\n    }\n  }\n}\nnode {\n  calculator: \"ImagePropertiesCalculator\"\n  input_stream: \"IMAGE:gated_image\"\n  output_stream: \"SIZE:gated_image_size\"\n}\nnode {\n  name: \"facelandmarkcpu__TfLiteCustomOpResolverCalculator\"\n  calculator: \"TfLiteCustomOpResolverCalculator\"\n  output_side_packet: \"OP_RESOLVER:facelandmarkcpu__op_resolver\"\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__ToImageCalculator\"\n  calculator: \"ToImageCalculator\"\n  input_stream: \"IMAGE:gated_image\"\n  output_stream: \"IMAGE:facedetectionshortrangecpu__facedetectionshortrange__facedetection__multi_backend_image\"\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__ImageToTensorCalculator\"\n  calculator: \"ImageToTensorCalculator\"\n  input_stream: \"IMAGE:facedetectionshortrangecpu__facedetectionshortrange__facedetection__multi_backend_image\"\n  output_stream: \"TENSORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__input_tensors\"\n  output_stream: \"MATRIX:facedetectionshortrangecpu__facedetectionshortrange__facedetection__transform_matrix\"\n  node_options {\n    type_url: \"type.googleapis.com/mediapipe.ImageToTensorCalculatorOptions\"\n    value: \"\\030\\001\"\\n\\r\\000\\000\\200\\277\\025\\000\\000\\200?0\\001\\010\\200\\001\\020\\200\\001\"\n  }\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__SsdAnchorsCalculator\"\n  calculator: \"SsdAnchorsCalculator\"\n  output_side_packet: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__anchors\"\n  node_options {\n    type_url: \"type.googleapis.com/mediapipe.SsdAnchorsCalculatorOptions\"\n    value: \"\\035\\000\\000\\030>%\\000\\000@?-\\000\\000\\000?5\\000\\000\\000?]\\000\\000\\200?p\\001\\010\\200\\001\\020\\200\\0018\\004P\\010P\\020P\\020P\\020m\\000\\000\\200?\"\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__switchcontainer__SwitchDemuxCalculator\"\n  calculator: \"SwitchDemuxCalculator\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    [mediapipe.SwitchContainerOptions.ext] {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__switchcontainer__ConstantSidePacketCalculator_1\"\n  calculator: \"ConstantSidePacketCalculator\"\n  output_side_packet: \"PACKET:facelandmarkcpu__facelandmarksmodelloader__switchcontainer__c0__facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  options {\n    [mediapipe.ConstantSidePacketCalculatorOptions.ext] {\n      packet {\n        string_value: \"mediapipe/modules/face_landmark/face_landmark.tflite\"\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__switchcontainer__ConstantSidePacketCalculator_2\"\n  calculator: \"ConstantSidePacketCalculator\"\n  output_side_packet: \"PACKET:facelandmarkcpu__facelandmarksmodelloader__switchcontainer__c1__facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  options {\n    [mediapipe.ConstantSidePacketCalculatorOptions.ext] {\n      packet {\n        string_value: \"mediapipe/modules/face_landmark/face_landmark_with_attention.tflite\"\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__switchcontainer__SwitchMuxCalculator\"\n  calculator: \"SwitchMuxCalculator\"\n  input_side_packet: \"ENABLE:with_attention\"\n  input_side_packet: \"C0__PACKET:facelandmarkcpu__facelandmarksmodelloader__switchcontainer__c0__facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  input_side_packet: \"C1__PACKET:facelandmarkcpu__facelandmarksmodelloader__switchcontainer__c1__facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  output_side_packet: \"PACKET:facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  options {\n    [mediapipe.SwitchContainerOptions.ext] {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__LocalFileContentsCalculator\"\n  calculator: \"LocalFileContentsCalculator\"\n  input_side_packet: \"FILE_PATH:facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  output_side_packet: \"CONTENTS:facelandmarkcpu__facelandmarksmodelloader__model_blob\"\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__TfLiteModelCalculator\"\n  calculator: \"TfLiteModelCalculator\"\n  input_side_packet: \"MODEL_BLOB:facelandmarkcpu__facelandmarksmodelloader__model_blob\"\n  output_side_packet: \"MODEL:facelandmarkcpu__model\"\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__inferencecalculator__facedetectionshortrangecpu__facedetectionshortrange__facedetection__InferenceCalculator\"\n  calculator: \"InferenceCalculatorCpu\"\n  input_stream: \"TENSORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__input_tensors\"\n  output_stream: \"TENSORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__detection_tensors\"\n  node_options {\n    type_url: \"type.googleapis.com/mediapipe.InferenceCalculatorOptions\"\n    value: \"*\\002\"\\000\\nBmediapipe/modules/face_detection/face_detection_short_range.tflite\"\n  }\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__TensorsToDetectionsCalculator\"\n  calculator: \"TensorsToDetectionsCalculator\"\n  input_stream: \"TENSORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__detection_tensors\"\n  output_stream: \"DETECTIONS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__unfiltered_detections\"\n  input_side_packet: \"ANCHORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__anchors\"\n  node_options {\n    type_url: \"type.googleapis.com/mediapipe.TensorsToDetectionsCalculatorOptions\"\n    value: \"\\010\\001\\020\\200\\007\\030\\020%\\000\\000\\000C-\\000\\000\\000C5\\000\\000\\000C=\\000\\000\\000CH\\004P\\006X\\002`\\000p\\001x\\001\\205\\001\\000\\000\\310B\\235\\001\\000\\000\\000?\"\n  }\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__NonMaxSuppressionCalculator\"\n  calculator: \"NonMaxSuppressionCalculator\"\n  input_stream: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__unfiltered_detections\"\n  output_stream: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__filtered_detections\"\n  options {\n    [mediapipe.NonMaxSuppressionCalculatorOptions.ext] {\n      min_suppression_threshold: 0.3\n      overlap_type: INTERSECTION_OVER_UNION\n      algorithm: WEIGHTED\n    }\n  }\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__DetectionProjectionCalculator\"\n  calculator: \"DetectionProjectionCalculator\"\n  input_stream: \"DETECTIONS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__filtered_detections\"\n  input_stream: \"PROJECTION_MATRIX:facedetectionshortrangecpu__facedetectionshortrange__facedetection__transform_matrix\"\n  output_stream: \"DETECTIONS:all_face_detections\"\n}\nnode {\n  calculator: \"ClipDetectionVectorSizeCalculator\"\n  input_stream: \"all_face_detections\"\n  output_stream: \"face_detections\"\n  input_side_packet: \"num_faces\"\n}\nnode {\n  calculator: \"BeginLoopDetectionCalculator\"\n  input_stream: \"ITERABLE:face_detections\"\n  input_stream: \"CLONE:gated_image_size\"\n  output_stream: \"ITEM:face_detection\"\n  output_stream: \"CLONE:detections_loop_image_size\"\n  output_stream: \"BATCH_END:detections_loop_end_timestamp\"\n}\nnode {\n  name: \"facedetectionfrontdetectiontoroi__DetectionsToRectsCalculator\"\n  calculator: \"DetectionsToRectsCalculator\"\n  input_stream: \"DETECTION:face_detection\"\n  input_stream: \"IMAGE_SIZE:detections_loop_image_size\"\n  output_stream: \"NORM_RECT:facedetectionfrontdetectiontoroi__initial_roi\"\n  options {\n    [mediapipe.DetectionsToRectsCalculatorOptions.ext] {\n      rotation_vector_start_keypoint_index: 0\n      rotation_vector_end_keypoint_index: 1\n      rotation_vector_target_angle_degrees: 0\n    }\n  }\n}\nnode {\n  name: \"facedetectionfrontdetectiontoroi__RectTransformationCalculator\"\n  calculator: \"RectTransformationCalculator\"\n  input_stream: \"NORM_RECT:facedetectionfrontdetectiontoroi__initial_roi\"\n  input_stream: \"IMAGE_SIZE:detections_loop_image_size\"\n  output_stream: \"face_rect_from_detection\"\n  options {\n    [mediapipe.RectTransformationCalculatorOptions.ext] {\n      scale_x: 1.5\n      scale_y: 1.5\n      square_long: true\n    }\n  }\n}\nnode {\n  calculator: \"EndLoopNormalizedRectCalculator\"\n  input_stream: \"ITEM:face_rect_from_detection\"\n  input_stream: \"BATCH_END:detections_loop_end_timestamp\"\n  output_stream: \"ITERABLE:face_rects_from_detections\"\n}\nnode {\n  calculator: \"AssociationNormRectCalculator\"\n  input_stream: \"face_rects_from_detections\"\n  input_stream: \"gated_prev_face_rects_from_landmarks\"\n  output_stream: \"face_rects\"\n  options {\n    [mediapipe.AssociationCalculatorOptions.ext] {\n      min_similarity_threshold: 0.5\n    }\n  }\n}\nnode {\n  calculator: \"BeginLoopNormalizedRectCalculator\"\n  input_stream: \"ITERABLE:face_rects\"\n  input_stream: \"CLONE:0:image\"\n  input_stream: \"CLONE:1:image_size\"\n  output_stream: \"ITEM:face_rect\"\n  output_stream: \"CLONE:0:landmarks_loop_image\"\n  output_stream: \"CLONE:1:landmarks_loop_image_size\"\n  output_stream: \"BATCH_END:landmarks_loop_end_timestamp\"\n}\nnode {\n  name: \"facelandmarkcpu__ImageToTensorCalculator\"\n  calculator: \"ImageToTensorCalculator\"\n  input_stream: \"IMAGE:landmarks_loop_image\"\n  input_stream: \"NORM_RECT:face_rect\"\n  output_stream: \"TENSORS:facelandmarkcpu__input_tensors\"\n  options {\n    [mediapipe.ImageToTensorCalculatorOptions.ext] {\n      output_tensor_width: 192\n      output_tensor_height: 192\n      output_tensor_float_range {\n        min: 0\n        max: 1\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__inferencecalculator__facelandmarkcpu__InferenceCalculator\"\n  calculator: \"InferenceCalculatorCpu\"\n  input_stream: \"TENSORS:facelandmarkcpu__input_tensors\"\n  output_stream: \"TENSORS:facelandmarkcpu__output_tensors\"\n  input_side_packet: \"MODEL:facelandmarkcpu__model\"\n  input_side_packet: \"OP_RESOLVER:facelandmarkcpu__op_resolver\"\n  options {\n    [mediapipe.InferenceCalculatorOptions.ext] {\n      delegate {\n        xnnpack {\n        }\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_1__SwitchDemuxCalculator\"\n  calculator: \"SwitchDemuxCalculator\"\n  input_stream: \"facelandmarkcpu__output_tensors\"\n  output_stream: \"C0__:facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__output_tensors\"\n  output_stream: \"C1__:facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__output_tensors\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    [mediapipe.SwitchContainerOptions.ext] {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_1__SplitTensorVectorCalculator_1\"\n  calculator: \"SplitTensorVectorCalculator\"\n  input_stream: \"facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__output_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__landmark_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__face_flag_tensor\"\n  options {\n    [mediapipe.SplitVectorCalculatorOptions.ext] {\n      ranges {\n        begin: 0\n        end: 1\n      }\n      ranges {\n        begin: 1\n        end: 2\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_1__SplitTensorVectorCalculator_2\"\n  calculator: \"SplitTensorVectorCalculator\"\n  input_stream: \"facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__output_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__landmark_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__face_flag_tensor\"\n  options {\n    [mediapipe.SplitVectorCalculatorOptions.ext] {\n      ranges {\n        begin: 0\n        end: 6\n      }\n      ranges {\n        begin: 6\n        end: 7\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_1__SwitchMuxCalculator\"\n  calculator: \"SwitchMuxCalculator\"\n  input_stream: \"C0__:facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__landmark_tensors\"\n  input_stream: \"C0__:1:facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__face_flag_tensor\"\n  input_stream: \"C1__:facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__landmark_tensors\"\n  input_stream: \"C1__:1:facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__face_flag_tensor\"\n  output_stream: \"facelandmarkcpu__landmark_tensors\"\n  output_stream: \"facelandmarkcpu__face_flag_tensor\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    [mediapipe.SwitchContainerOptions.ext] {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__TensorsToFloatsCalculator\"\n  calculator: \"TensorsToFloatsCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__face_flag_tensor\"\n  output_stream: \"FLOAT:facelandmarkcpu__face_presence_score\"\n  options {\n    [mediapipe.TensorsToFloatsCalculatorOptions.ext] {\n      activation: SIGMOID\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__ThresholdingCalculator\"\n  calculator: \"ThresholdingCalculator\"\n  input_stream: \"FLOAT:facelandmarkcpu__face_presence_score\"\n  output_stream: \"FLAG:facelandmarkcpu__face_presence\"\n  options {\n    [mediapipe.ThresholdingCalculatorOptions.ext] {\n      threshold: 0.5\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__GateCalculator\"\n  calculator: \"GateCalculator\"\n  input_stream: \"facelandmarkcpu__landmark_tensors\"\n  input_stream: \"ALLOW:facelandmarkcpu__face_presence\"\n  output_stream: \"facelandmarkcpu__ensured_landmark_tensors\"\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__SwitchDemuxCalculator\"\n  calculator: \"SwitchDemuxCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__ensured_landmark_tensors\"\n  output_stream: \"C0__TENSORS:facelandmarkcpu__switchcontainer_2__c0__facelandmarkcpu__ensured_landmark_tensors\"\n  output_stream: \"C1__TENSORS:facelandmarkcpu__switchcontainer_2__c1__facelandmarkcpu__ensured_landmark_tensors\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    [mediapipe.SwitchContainerOptions.ext] {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarks__TensorsToLandmarksCalculator\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__c0__facelandmarkcpu__ensured_landmark_tensors\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__c0__facelandmarkcpu__landmarks\"\n  options {\n    [mediapipe.TensorsToLandmarksCalculatorOptions.ext] {\n      num_landmarks: 468\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__SplitTensorVectorCalculator\"\n  calculator: \"SplitTensorVectorCalculator\"\n  input_stream: \"facelandmarkcpu__switchcontainer_2__c1__facelandmarkcpu__ensured_landmark_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__mesh_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__lips_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_eye_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_eye_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_iris_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_iris_tensor\"\n  options {\n    [mediapipe.SplitVectorCalculatorOptions.ext] {\n      ranges {\n        begin: 0\n        end: 1\n      }\n      ranges {\n        begin: 1\n        end: 2\n      }\n      ranges {\n        begin: 2\n        end: 3\n      }\n      ranges {\n        begin: 3\n        end: 4\n      }\n      ranges {\n        begin: 4\n        end: 5\n      }\n      ranges {\n        begin: 5\n        end: 6\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_1\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__mesh_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__mesh_landmarks\"\n  options {\n    [mediapipe.TensorsToLandmarksCalculatorOptions.ext] {\n      num_landmarks: 468\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_2\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__lips_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__lips_landmarks\"\n  options {\n    [mediapipe.TensorsToLandmarksCalculatorOptions.ext] {\n      num_landmarks: 80\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_3\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_eye_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_eye_landmarks\"\n  options {\n    [mediapipe.TensorsToLandmarksCalculatorOptions.ext] {\n      num_landmarks: 71\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_4\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_eye_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_eye_landmarks\"\n  options {\n    [mediapipe.TensorsToLandmarksCalculatorOptions.ext] {\n      num_landmarks: 71\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_5\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_iris_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_iris_landmarks\"\n  options {\n    [mediapipe.TensorsToLandmarksCalculatorOptions.ext] {\n      num_landmarks: 5\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_6\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_iris_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_iris_landmarks\"\n  options {\n    [mediapipe.TensorsToLandmarksCalculatorOptions.ext] {\n      num_landmarks: 5\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__LandmarksRefinementCalculator\"\n  calculator: \"LandmarksRefinementCalculator\"\n  input_stream: \"LANDMARKS:0:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__mesh_landmarks\"\n  input_stream: \"LANDMARKS:1:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__lips_landmarks\"\n  input_stream: \"LANDMARKS:2:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_eye_landmarks\"\n  input_stream: \"LANDMARKS:3:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_eye_landmarks\"\n  input_stream: \"LANDMARKS:4:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_iris_landmarks\"\n  input_stream: \"LANDMARKS:5:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_iris_landmarks\"\n  output_stream: \"REFINED_LANDMARKS:facelandmarkcpu__switchcontainer_2__c1__facelandmarkcpu__landmarks\"\n  options {\n    [mediapipe.LandmarksRefinementCalculatorOptions.ext] {\n      refinement {\n        indexes_mapping: 0\n        indexes_mapping: 1\n        indexes_mapping: 2\n        indexes_mapping: 3\n        indexes_mapping: 4\n        indexes_mapping: 5\n        indexes_mapping: 6\n        indexes_mapping: 7\n        indexes_mapping: 8\n        indexes_mapping: 9\n        indexes_mapping: 10\n        indexes_mapping: 11\n        indexes_mapping: 12\n        indexes_mapping: 13\n        indexes_mapping: 14\n        indexes_mapping: 15\n        indexes_mapping: 16\n        indexes_mapping: 17\n        indexes_mapping: 18\n        indexes_mapping: 19\n        indexes_mapping: 20\n        indexes_mapping: 21\n        indexes_mapping: 22\n        indexes_mapping: 23\n        indexes_mapping: 24\n        indexes_mapping: 25\n        indexes_mapping: 26\n        indexes_mapping: 27\n        indexes_mapping: 28\n        indexes_mapping: 29\n        indexes_mapping: 30\n        indexes_mapping: 31\n        indexes_mapping: 32\n        indexes_mapping: 33\n        indexes_mapping: 34\n        indexes_mapping: 35\n        indexes_mapping: 36\n        indexes_mapping: 37\n        indexes_mapping: 38\n        indexes_mapping: 39\n        indexes_mapping: 40\n        indexes_mapping: 41\n        indexes_mapping: 42\n        indexes_mapping: 43\n        indexes_mapping: 44\n        indexes_mapping: 45\n        indexes_mapping: 46\n        indexes_mapping: 47\n        indexes_mapping: 48\n        indexes_mapping: 49\n        indexes_mapping: 50\n        indexes_mapping: 51\n        indexes_mapping: 52\n        indexes_mapping: 53\n        indexes_mapping: 54\n        indexes_mapping: 55\n        indexes_mapping: 56\n        indexes_mapping: 57\n        indexes_mapping: 58\n        indexes_mapping: 59\n        indexes_mapping: 60\n        indexes_mapping: 61\n        indexes_mapping: 62\n        indexes_mapping: 63\n        indexes_mapping: 64\n        indexes_mapping: 65\n        indexes_mapping: 66\n        indexes_mapping: 67\n        indexes_mapping: 68\n        indexes_mapping: 69\n        indexes_mapping: 70\n        indexes_mapping: 71\n        indexes_mapping: 72\n        indexes_mapping: 73\n        indexes_mapping: 74\n        indexes_mapping: 75\n        indexes_mapping: 76\n        indexes_mapping: 77\n        indexes_mapping: 78\n        indexes_mapping: 79\n        indexes_mapping: 80\n        indexes_mapping: 81\n        indexes_mapping: 82\n        indexes_mapping: 83\n        indexes_mapping: 84\n        indexes_mapping: 85\n        indexes_mapping: 86\n        indexes_mapping: 87\n        indexes_mapping: 88\n        indexes_mapping: 89\n        indexes_mapping: 90\n        indexes_mapping: 91\n        indexes_mapping: 92\n        indexes_mapping: 93\n        indexes_mapping: 94\n        indexes_mapping: 95\n        indexes_mapping: 96\n        indexes_mapping: 97\n        indexes_mapping: 98\n        indexes_mapping: 99\n        indexes_mapping: 100\n        indexes_mapping: 101\n        indexes_mapping: 102\n        indexes_mapping: 103\n        indexes_mapping: 104\n        indexes_mapping: 105\n        indexes_mapping: 106\n        indexes_mapping: 107\n        indexes_mapping: 108\n        indexes_mapping: 109\n        indexes_mapping: 110\n        indexes_mapping: 111\n        indexes_mapping: 112\n        indexes_mapping: 113\n        indexes_mapping: 114\n        indexes_mapping: 115\n        indexes_mapping: 116\n        indexes_mapping: 117\n        indexes_mapping: 118\n        indexes_mapping: 119\n        indexes_mapping: 120\n        indexes_mapping: 121\n        indexes_mapping: 122\n        indexes_mapping: 123\n        indexes_mapping: 124\n        indexes_mapping: 125\n        indexes_mapping: 126\n        indexes_mapping: 127\n        indexes_mapping: 128\n        indexes_mapping: 129\n        indexes_mapping: 130\n        indexes_mapping: 131\n        indexes_mapping: 132\n        indexes_mapping: 133\n        indexes_mapping: 134\n        indexes_mapping: 135\n        indexes_mapping: 136\n        indexes_mapping: 137\n        indexes_mapping: 138\n        indexes_mapping: 139\n        indexes_mapping: 140\n        indexes_mapping: 141\n        indexes_mapping: 142\n        indexes_mapping: 143\n        indexes_mapping: 144\n        indexes_mapping: 145\n        indexes_mapping: 146\n        indexes_mapping: 147\n        indexes_mapping: 148\n        indexes_mapping: 149\n        indexes_mapping: 150\n        indexes_mapping: 151\n        indexes_mapping: 152\n        indexes_mapping: 153\n        indexes_mapping: 154\n        indexes_mapping: 155\n        indexes_mapping: 156\n        indexes_mapping: 157\n        indexes_mapping: 158\n        indexes_mapping: 159\n        indexes_mapping: 160\n        indexes_mapping: 161\n        indexes_mapping: 162\n        indexes_mapping: 163\n        indexes_mapping: 164\n        indexes_mapping: 165\n        indexes_mapping: 166\n        indexes_mapping: 167\n        indexes_mapping: 168\n        indexes_mapping: 169\n        indexes_mapping: 170\n        indexes_mapping: 171\n        indexes_mapping: 172\n        indexes_mapping: 173\n        indexes_mapping: 174\n        indexes_mapping: 175\n        indexes_mapping: 176\n        indexes_mapping: 177\n        indexes_mapping: 178\n        indexes_mapping: 179\n        indexes_mapping: 180\n        indexes_mapping: 181\n        indexes_mapping: 182\n        indexes_mapping: 183\n        indexes_mapping: 184\n        indexes_mapping: 185\n        indexes_mapping: 186\n        indexes_mapping: 187\n        indexes_mapping: 188\n        indexes_mapping: 189\n        indexes_mapping: 190\n        indexes_mapping: 191\n        indexes_mapping: 192\n        indexes_mapping: 193\n        indexes_mapping: 194\n        indexes_mapping: 195\n        indexes_mapping: 196\n        indexes_mapping: 197\n        indexes_mapping: 198\n        indexes_mapping: 199\n        indexes_mapping: 200\n        indexes_mapping: 201\n        indexes_mapping: 202\n        indexes_mapping: 203\n        indexes_mapping: 204\n        indexes_mapping: 205\n        indexes_mapping: 206\n        indexes_mapping: 207\n        indexes_mapping: 208\n        indexes_mapping: 209\n        indexes_mapping: 210\n        indexes_mapping: 211\n        indexes_mapping: 212\n        indexes_mapping: 213\n        indexes_mapping: 214\n        indexes_mapping: 215\n        indexes_mapping: 216\n        indexes_mapping: 217\n        indexes_mapping: 218\n        indexes_mapping: 219\n        indexes_mapping: 220\n        indexes_mapping: 221\n        indexes_mapping: 222\n        indexes_mapping: 223\n        indexes_mapping: 224\n        indexes_mapping: 225\n        indexes_mapping: 226\n        indexes_mapping: 227\n        indexes_mapping: 228\n        indexes_mapping: 229\n        indexes_mapping: 230\n        indexes_mapping: 231\n        indexes_mapping: 232\n        indexes_mapping: 233\n        indexes_mapping: 234\n        indexes_mapping: 235\n        indexes_mapping: 236\n        indexes_mapping: 237\n        indexes_mapping: 238\n        indexes_mapping: 239\n        indexes_mapping: 240\n        indexes_mapping: 241\n        indexes_mapping: 242\n        indexes_mapping: 243\n        indexes_mapping: 244\n        indexes_mapping: 245\n        indexes_mapping: 246\n        indexes_mapping: 247\n        indexes_mapping: 248\n        indexes_mapping: 249\n        indexes_mapping: 250\n        indexes_mapping: 251\n        indexes_mapping: 252\n        indexes_mapping: 253\n        indexes_mapping: 254\n        indexes_mapping: 255\n        indexes_mapping: 256\n        indexes_mapping: 257\n        indexes_mapping: 258\n        indexes_mapping: 259\n        indexes_mapping: 260\n        indexes_mapping: 261\n        indexes_mapping: 262\n        indexes_mapping: 263\n        indexes_mapping: 264\n        indexes_mapping: 265\n        indexes_mapping: 266\n        indexes_mapping: 267\n        indexes_mapping: 268\n        indexes_mapping: 269\n        indexes_mapping: 270\n        indexes_mapping: 271\n        indexes_mapping: 272\n        indexes_mapping: 273\n        indexes_mapping: 274\n        indexes_mapping: 275\n        indexes_mapping: 276\n        indexes_mapping: 277\n        indexes_mapping: 278\n        indexes_mapping: 279\n        indexes_mapping: 280\n        indexes_mapping: 281\n        indexes_mapping: 282\n        indexes_mapping: 283\n        indexes_mapping: 284\n        indexes_mapping: 285\n        indexes_mapping: 286\n        indexes_mapping: 287\n        indexes_mapping: 288\n        indexes_mapping: 289\n        indexes_mapping: 290\n        indexes_mapping: 291\n        indexes_mapping: 292\n        indexes_mapping: 293\n        indexes_mapping: 294\n        indexes_mapping: 295\n        indexes_mapping: 296\n        indexes_mapping: 297\n        indexes_mapping: 298\n        indexes_mapping: 299\n        indexes_mapping: 300\n        indexes_mapping: 301\n        indexes_mapping: 302\n        indexes_mapping: 303\n        indexes_mapping: 304\n        indexes_mapping: 305\n        indexes_mapping: 306\n        indexes_mapping: 307\n        indexes_mapping: 308\n        indexes_mapping: 309\n        indexes_mapping: 310\n        indexes_mapping: 311\n        indexes_mapping: 312\n        indexes_mapping: 313\n        indexes_mapping: 314\n        indexes_mapping: 315\n        indexes_mapping: 316\n        indexes_mapping: 317\n        indexes_mapping: 318\n        indexes_mapping: 319\n        indexes_mapping: 320\n        indexes_mapping: 321\n        indexes_mapping: 322\n        indexes_mapping: 323\n        indexes_mapping: 324\n        indexes_mapping: 325\n        indexes_mapping: 326\n        indexes_mapping: 327\n        indexes_mapping: 328\n        indexes_mapping: 329\n        indexes_mapping: 330\n        indexes_mapping: 331\n        indexes_mapping: 332\n        indexes_mapping: 333\n        indexes_mapping: 334\n        indexes_mapping: 335\n        indexes_mapping: 336\n        indexes_mapping: 337\n        indexes_mapping: 338\n        indexes_mapping: 339\n        indexes_mapping: 340\n        indexes_mapping: 341\n        indexes_mapping: 342\n        indexes_mapping: 343\n        indexes_mapping: 344\n        indexes_mapping: 345\n        indexes_mapping: 346\n        indexes_mapping: 347\n        indexes_mapping: 348\n        indexes_mapping: 349\n        indexes_mapping: 350\n        indexes_mapping: 351\n        indexes_mapping: 352\n        indexes_mapping: 353\n        indexes_mapping: 354\n        indexes_mapping: 355\n        indexes_mapping: 356\n        indexes_mapping: 357\n        indexes_mapping: 358\n        indexes_mapping: 359\n        indexes_mapping: 360\n        indexes_mapping: 361\n        indexes_mapping: 362\n        indexes_mapping: 363\n        indexes_mapping: 364\n        indexes_mapping: 365\n        indexes_mapping: 366\n        indexes_mapping: 367\n        indexes_mapping: 368\n        indexes_mapping: 369\n        indexes_mapping: 370\n        indexes_mapping: 371\n        indexes_mapping: 372\n        indexes_mapping: 373\n        indexes_mapping: 374\n        indexes_mapping: 375\n        indexes_mapping: 376\n        indexes_mapping: 377\n        indexes_mapping: 378\n        indexes_mapping: 379\n        indexes_mapping: 380\n        indexes_mapping: 381\n        indexes_mapping: 382\n        indexes_mapping: 383\n        indexes_mapping: 384\n        indexes_mapping: 385\n        indexes_mapping: 386\n        indexes_mapping: 387\n        indexes_mapping: 388\n        indexes_mapping: 389\n        indexes_mapping: 390\n        indexes_mapping: 391\n        indexes_mapping: 392\n        indexes_mapping: 393\n        indexes_mapping: 394\n        indexes_mapping: 395\n        indexes_mapping: 396\n        indexes_mapping: 397\n        indexes_mapping: 398\n        indexes_mapping: 399\n        indexes_mapping: 400\n        indexes_mapping: 401\n        indexes_mapping: 402\n        indexes_mapping: 403\n        indexes_mapping: 404\n        indexes_mapping: 405\n        indexes_mapping: 406\n        indexes_mapping: 407\n        indexes_mapping: 408\n        indexes_mapping: 409\n        indexes_mapping: 410\n        indexes_mapping: 411\n        indexes_mapping: 412\n        indexes_mapping: 413\n        indexes_mapping: 414\n        indexes_mapping: 415\n        indexes_mapping: 416\n        indexes_mapping: 417\n        indexes_mapping: 418\n        indexes_mapping: 419\n        indexes_mapping: 420\n        indexes_mapping: 421\n        indexes_mapping: 422\n        indexes_mapping: 423\n        indexes_mapping: 424\n        indexes_mapping: 425\n        indexes_mapping: 426\n        indexes_mapping: 427\n        indexes_mapping: 428\n        indexes_mapping: 429\n        indexes_mapping: 430\n        indexes_mapping: 431\n        indexes_mapping: 432\n        indexes_mapping: 433\n        indexes_mapping: 434\n        indexes_mapping: 435\n        indexes_mapping: 436\n        indexes_mapping: 437\n        indexes_mapping: 438\n        indexes_mapping: 439\n        indexes_mapping: 440\n        indexes_mapping: 441\n        indexes_mapping: 442\n        indexes_mapping: 443\n        indexes_mapping: 444\n        indexes_mapping: 445\n        indexes_mapping: 446\n        indexes_mapping: 447\n        indexes_mapping: 448\n        indexes_mapping: 449\n        indexes_mapping: 450\n        indexes_mapping: 451\n        indexes_mapping: 452\n        indexes_mapping: 453\n        indexes_mapping: 454\n        indexes_mapping: 455\n        indexes_mapping: 456\n        indexes_mapping: 457\n        indexes_mapping: 458\n        indexes_mapping: 459\n        indexes_mapping: 460\n        indexes_mapping: 461\n        indexes_mapping: 462\n        indexes_mapping: 463\n        indexes_mapping: 464\n        indexes_mapping: 465\n        indexes_mapping: 466\n        indexes_mapping: 467\n        z_refinement {\n          copy {\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 61\n        indexes_mapping: 146\n        indexes_mapping: 91\n        indexes_mapping: 181\n        indexes_mapping: 84\n        indexes_mapping: 17\n        indexes_mapping: 314\n        indexes_mapping: 405\n        indexes_mapping: 321\n        indexes_mapping: 375\n        indexes_mapping: 291\n        indexes_mapping: 185\n        indexes_mapping: 40\n        indexes_mapping: 39\n        indexes_mapping: 37\n        indexes_mapping: 0\n        indexes_mapping: 267\n        indexes_mapping: 269\n        indexes_mapping: 270\n        indexes_mapping: 409\n        indexes_mapping: 78\n        indexes_mapping: 95\n        indexes_mapping: 88\n        indexes_mapping: 178\n        indexes_mapping: 87\n        indexes_mapping: 14\n        indexes_mapping: 317\n        indexes_mapping: 402\n        indexes_mapping: 318\n        indexes_mapping: 324\n        indexes_mapping: 308\n        indexes_mapping: 191\n        indexes_mapping: 80\n        indexes_mapping: 81\n        indexes_mapping: 82\n        indexes_mapping: 13\n        indexes_mapping: 312\n        indexes_mapping: 311\n        indexes_mapping: 310\n        indexes_mapping: 415\n        indexes_mapping: 76\n        indexes_mapping: 77\n        indexes_mapping: 90\n        indexes_mapping: 180\n        indexes_mapping: 85\n        indexes_mapping: 16\n        indexes_mapping: 315\n        indexes_mapping: 404\n        indexes_mapping: 320\n        indexes_mapping: 307\n        indexes_mapping: 306\n        indexes_mapping: 184\n        indexes_mapping: 74\n        indexes_mapping: 73\n        indexes_mapping: 72\n        indexes_mapping: 11\n        indexes_mapping: 302\n        indexes_mapping: 303\n        indexes_mapping: 304\n        indexes_mapping: 408\n        indexes_mapping: 62\n        indexes_mapping: 96\n        indexes_mapping: 89\n        indexes_mapping: 179\n        indexes_mapping: 86\n        indexes_mapping: 15\n        indexes_mapping: 316\n        indexes_mapping: 403\n        indexes_mapping: 319\n        indexes_mapping: 325\n        indexes_mapping: 292\n        indexes_mapping: 183\n        indexes_mapping: 42\n        indexes_mapping: 41\n        indexes_mapping: 38\n        indexes_mapping: 12\n        indexes_mapping: 268\n        indexes_mapping: 271\n        indexes_mapping: 272\n        indexes_mapping: 407\n        z_refinement {\n          none {\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 33\n        indexes_mapping: 7\n        indexes_mapping: 163\n        indexes_mapping: 144\n        indexes_mapping: 145\n        indexes_mapping: 153\n        indexes_mapping: 154\n        indexes_mapping: 155\n        indexes_mapping: 133\n        indexes_mapping: 246\n        indexes_mapping: 161\n        indexes_mapping: 160\n        indexes_mapping: 159\n        indexes_mapping: 158\n        indexes_mapping: 157\n        indexes_mapping: 173\n        indexes_mapping: 130\n        indexes_mapping: 25\n        indexes_mapping: 110\n        indexes_mapping: 24\n        indexes_mapping: 23\n        indexes_mapping: 22\n        indexes_mapping: 26\n        indexes_mapping: 112\n        indexes_mapping: 243\n        indexes_mapping: 247\n        indexes_mapping: 30\n        indexes_mapping: 29\n        indexes_mapping: 27\n        indexes_mapping: 28\n        indexes_mapping: 56\n        indexes_mapping: 190\n        indexes_mapping: 226\n        indexes_mapping: 31\n        indexes_mapping: 228\n        indexes_mapping: 229\n        indexes_mapping: 230\n        indexes_mapping: 231\n        indexes_mapping: 232\n        indexes_mapping: 233\n        indexes_mapping: 244\n        indexes_mapping: 113\n        indexes_mapping: 225\n        indexes_mapping: 224\n        indexes_mapping: 223\n        indexes_mapping: 222\n        indexes_mapping: 221\n        indexes_mapping: 189\n        indexes_mapping: 35\n        indexes_mapping: 124\n        indexes_mapping: 46\n        indexes_mapping: 53\n        indexes_mapping: 52\n        indexes_mapping: 65\n        indexes_mapping: 143\n        indexes_mapping: 111\n        indexes_mapping: 117\n        indexes_mapping: 118\n        indexes_mapping: 119\n        indexes_mapping: 120\n        indexes_mapping: 121\n        indexes_mapping: 128\n        indexes_mapping: 245\n        indexes_mapping: 156\n        indexes_mapping: 70\n        indexes_mapping: 63\n        indexes_mapping: 105\n        indexes_mapping: 66\n        indexes_mapping: 107\n        indexes_mapping: 55\n        indexes_mapping: 193\n        z_refinement {\n          none {\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 263\n        indexes_mapping: 249\n        indexes_mapping: 390\n        indexes_mapping: 373\n        indexes_mapping: 374\n        indexes_mapping: 380\n        indexes_mapping: 381\n        indexes_mapping: 382\n        indexes_mapping: 362\n        indexes_mapping: 466\n        indexes_mapping: 388\n        indexes_mapping: 387\n        indexes_mapping: 386\n        indexes_mapping: 385\n        indexes_mapping: 384\n        indexes_mapping: 398\n        indexes_mapping: 359\n        indexes_mapping: 255\n        indexes_mapping: 339\n        indexes_mapping: 254\n        indexes_mapping: 253\n        indexes_mapping: 252\n        indexes_mapping: 256\n        indexes_mapping: 341\n        indexes_mapping: 463\n        indexes_mapping: 467\n        indexes_mapping: 260\n        indexes_mapping: 259\n        indexes_mapping: 257\n        indexes_mapping: 258\n        indexes_mapping: 286\n        indexes_mapping: 414\n        indexes_mapping: 446\n        indexes_mapping: 261\n        indexes_mapping: 448\n        indexes_mapping: 449\n        indexes_mapping: 450\n        indexes_mapping: 451\n        indexes_mapping: 452\n        indexes_mapping: 453\n        indexes_mapping: 464\n        indexes_mapping: 342\n        indexes_mapping: 445\n        indexes_mapping: 444\n        indexes_mapping: 443\n        indexes_mapping: 442\n        indexes_mapping: 441\n        indexes_mapping: 413\n        indexes_mapping: 265\n        indexes_mapping: 353\n        indexes_mapping: 276\n        indexes_mapping: 283\n        indexes_mapping: 282\n        indexes_mapping: 295\n        indexes_mapping: 372\n        indexes_mapping: 340\n        indexes_mapping: 346\n        indexes_mapping: 347\n        indexes_mapping: 348\n        indexes_mapping: 349\n        indexes_mapping: 350\n        indexes_mapping: 357\n        indexes_mapping: 465\n        indexes_mapping: 383\n        indexes_mapping: 300\n        indexes_mapping: 293\n        indexes_mapping: 334\n        indexes_mapping: 296\n        indexes_mapping: 336\n        indexes_mapping: 285\n        indexes_mapping: 417\n        z_refinement {\n          none {\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 468\n        indexes_mapping: 469\n        indexes_mapping: 470\n        indexes_mapping: 471\n        indexes_mapping: 472\n        z_refinement {\n          assign_average {\n            indexes_for_average: 33\n            indexes_for_average: 7\n            indexes_for_average: 163\n            indexes_for_average: 144\n            indexes_for_average: 145\n            indexes_for_average: 153\n            indexes_for_average: 154\n            indexes_for_average: 155\n            indexes_for_average: 133\n            indexes_for_average: 246\n            indexes_for_average: 161\n            indexes_for_average: 160\n            indexes_for_average: 159\n            indexes_for_average: 158\n            indexes_for_average: 157\n            indexes_for_average: 173\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 473\n        indexes_mapping: 474\n        indexes_mapping: 475\n        indexes_mapping: 476\n        indexes_mapping: 477\n        z_refinement {\n          assign_average {\n            indexes_for_average: 263\n            indexes_for_average: 249\n            indexes_for_average: 390\n            indexes_for_average: 373\n            indexes_for_average: 374\n            indexes_for_average: 380\n            indexes_for_average: 381\n            indexes_for_average: 382\n            indexes_for_average: 362\n            indexes_for_average: 466\n            indexes_for_average: 388\n            indexes_for_average: 387\n            indexes_for_average: 386\n            indexes_for_average: 385\n            indexes_for_average: 384\n            indexes_for_average: 398\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__SwitchMuxCalculator\"\n  calculator: \"SwitchMuxCalculator\"\n  input_stream: \"C0__LANDMARKS:facelandmarkcpu__switchcontainer_2__c0__facelandmarkcpu__landmarks\"\n  input_stream: \"C1__LANDMARKS:facelandmarkcpu__switchcontainer_2__c1__facelandmarkcpu__landmarks\"\n  output_stream: \"LANDMARKS:facelandmarkcpu__landmarks\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    [mediapipe.SwitchContainerOptions.ext] {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__LandmarkProjectionCalculator\"\n  calculator: \"LandmarkProjectionCalculator\"\n  input_stream: \"NORM_LANDMARKS:facelandmarkcpu__landmarks\"\n  input_stream: \"NORM_RECT:face_rect\"\n  output_stream: \"NORM_LANDMARKS:face_landmarks\"\n}\nnode {\n  calculator: \"EndLoopNormalizedLandmarkListVectorCalculator\"\n  input_stream: \"ITEM:face_landmarks\"\n  input_stream: \"BATCH_END:landmarks_loop_end_timestamp\"\n  output_stream: \"ITERABLE:multi_face_landmarks\"\n}\nnode {\n  name: \"facelandmarklandmarkstoroi__LandmarksToDetectionCalculator\"\n  calculator: \"LandmarksToDetectionCalculator\"\n  input_stream: \"NORM_LANDMARKS:face_landmarks\"\n  output_stream: \"DETECTION:facelandmarklandmarkstoroi__face_detection\"\n}\nnode {\n  name: \"facelandmarklandmarkstoroi__DetectionsToRectsCalculator\"\n  calculator: \"DetectionsToRectsCalculator\"\n  input_stream: \"DETECTION:facelandmarklandmarkstoroi__face_detection\"\n  input_stream: \"IMAGE_SIZE:landmarks_loop_image_size\"\n  output_stream: \"NORM_RECT:facelandmarklandmarkstoroi__face_rect_from_landmarks\"\n  options {\n    [mediapipe.DetectionsToRectsCalculatorOptions.ext] {\n      rotation_vector_start_keypoint_index: 33\n      rotation_vector_end_keypoint_index: 263\n      rotation_vector_target_angle_degrees: 0\n    }\n  }\n}\nnode {\n  name: \"facelandmarklandmarkstoroi__RectTransformationCalculator\"\n  calculator: \"RectTransformationCalculator\"\n  input_stream: \"NORM_RECT:facelandmarklandmarkstoroi__face_rect_from_landmarks\"\n  input_stream: \"IMAGE_SIZE:landmarks_loop_image_size\"\n  output_stream: \"face_rect_from_landmarks\"\n  options {\n    [mediapipe.RectTransformationCalculatorOptions.ext] {\n      scale_x: 1.5\n      scale_y: 1.5\n      square_long: true\n    }\n  }\n}\nnode {\n  calculator: \"EndLoopNormalizedRectCalculator\"\n  input_stream: \"ITEM:face_rect_from_landmarks\"\n  input_stream: \"BATCH_END:landmarks_loop_end_timestamp\"\n  output_stream: \"ITERABLE:face_rects_from_landmarks\"\n}\ninput_stream: \"IMAGE:image\"\nexecutor {\n}\noutput_stream: \"LANDMARKS:multi_face_landmarks\"\noutput_stream: \"DETECTIONS:face_detections\"\noutput_stream: \"ROIS_FROM_LANDMARKS:face_rects_from_landmarks\"\noutput_stream: \"ROIS_FROM_DETECTIONS:face_rects_from_detections\"\ninput_side_packet: \"NUM_FACES:num_faces\"\ninput_side_packet: \"USE_PREV_LANDMARKS:use_prev_landmarks\"\ninput_side_packet: \"WITH_ATTENTION:with_attention\"\ntype: \"FaceLandmarkFrontCpu\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 307\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    305\u001b[0m \u001b[38;5;66;03m#     video_path = 'C:/Users/DIACTO/Videos/Captures/2-3 min introduction video.mp4'  # Replace with the desired video file path\u001b[39;00m\n\u001b[0;32m    306\u001b[0m     video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/Vaishnavi/Downloads/5442623-hd_1280_720_25fps.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 307\u001b[0m     final_results \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    310\u001b[0m         \u001b[38;5;28mprint\u001b[39m(final_results)\n",
      "Cell \u001b[1;32mIn[1], line 207\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(video_path)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmap_face_mesh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFaceMesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrefine_landmarks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_detection_confidence\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_tracking_confidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m face_mesh:\n\u001b[0;32m    208\u001b[0m \n\u001b[0;32m    209\u001b[0m     \u001b[38;5;66;03m# starting time here \u001b[39;00m\n\u001b[0;32m    210\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# starting Video loop here.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mediapipe\\python\\solutions\\face_mesh.py:95\u001b[0m, in \u001b[0;36mFaceMesh.__init__\u001b[1;34m(self, static_image_mode, max_num_faces, refine_landmarks, min_detection_confidence, min_tracking_confidence)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     71\u001b[0m              static_image_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m              max_num_faces\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     73\u001b[0m              refine_landmarks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     74\u001b[0m              min_detection_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[0;32m     75\u001b[0m              min_tracking_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m):\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Initializes a MediaPipe Face Mesh object.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m      https://solutions.mediapipe.dev/face_mesh#min_tracking_confidence.\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbinary_graph_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_BINARYPB_FILE_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m      \u001b[49m\u001b[43mside_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_faces\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_num_faces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwith_attention\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefine_landmarks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muse_prev_landmarks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstatic_image_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m      \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcalculator_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfacedetectionshortrangecpu__facedetectionshortrange__facedetection__TensorsToDetectionsCalculator.min_score_thresh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmin_detection_confidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfacelandmarkcpu__ThresholdingCalculator.threshold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmin_tracking_confidence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m      \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulti_face_landmarks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:248\u001b[0m, in \u001b[0;36mSolutionBase.__init__\u001b[1;34m(self, binary_graph_path, graph_config, calculator_params, graph_options, side_inputs, outputs, stream_type_hints)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m graph_options:\n\u001b[0;32m    245\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_extension(canonical_graph_config_proto\u001b[38;5;241m.\u001b[39mgraph_options,\n\u001b[0;32m    246\u001b[0m                       graph_options)\n\u001b[1;32m--> 248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph \u001b[38;5;241m=\u001b[39m \u001b[43mcalculator_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCalculatorGraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcanonical_graph_config_proto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_outputs \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to parse: node {\n  calculator: \"ImagePropertiesCalculator\"\n  input_stream: \"IMAGE:image\"\n  output_stream: \"SIZE:image_size\"\n}\nnode {\n  calculator: \"PreviousLoopbackCalculator\"\n  input_stream: \"MAIN:image\"\n  input_stream: \"LOOP:face_rects_from_landmarks\"\n  output_stream: \"PREV_LOOP:prev_face_rects_from_landmarks\"\n  input_stream_info {\n    tag_index: \"LOOP\"\n    back_edge: true\n  }\n}\nnode {\n  calculator: \"GateCalculator\"\n  input_stream: \"prev_face_rects_from_landmarks\"\n  output_stream: \"gated_prev_face_rects_from_landmarks\"\n  input_side_packet: \"ALLOW:use_prev_landmarks\"\n  options {\n    [mediapipe.GateCalculatorOptions.ext] {\n      allow: true\n    }\n  }\n}\nnode {\n  calculator: \"NormalizedRectVectorHasMinSizeCalculator\"\n  input_stream: \"ITERABLE:gated_prev_face_rects_from_landmarks\"\n  output_stream: \"prev_has_enough_faces\"\n  input_side_packet: \"num_faces\"\n}\nnode {\n  calculator: \"GateCalculator\"\n  input_stream: \"image\"\n  input_stream: \"DISALLOW:prev_has_enough_faces\"\n  output_stream: \"gated_image\"\n  options {\n    [mediapipe.GateCalculatorOptions.ext] {\n      empty_packets_as_allow: true\n    }\n  }\n}\nnode {\n  calculator: \"ImagePropertiesCalculator\"\n  input_stream: \"IMAGE:gated_image\"\n  output_stream: \"SIZE:gated_image_size\"\n}\nnode {\n  name: \"facelandmarkcpu__TfLiteCustomOpResolverCalculator\"\n  calculator: \"TfLiteCustomOpResolverCalculator\"\n  output_side_packet: \"OP_RESOLVER:facelandmarkcpu__op_resolver\"\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__ToImageCalculator\"\n  calculator: \"ToImageCalculator\"\n  input_stream: \"IMAGE:gated_image\"\n  output_stream: \"IMAGE:facedetectionshortrangecpu__facedetectionshortrange__facedetection__multi_backend_image\"\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__ImageToTensorCalculator\"\n  calculator: \"ImageToTensorCalculator\"\n  input_stream: \"IMAGE:facedetectionshortrangecpu__facedetectionshortrange__facedetection__multi_backend_image\"\n  output_stream: \"TENSORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__input_tensors\"\n  output_stream: \"MATRIX:facedetectionshortrangecpu__facedetectionshortrange__facedetection__transform_matrix\"\n  node_options {\n    type_url: \"type.googleapis.com/mediapipe.ImageToTensorCalculatorOptions\"\n    value: \"\\030\\001\"\\n\\r\\000\\000\\200\\277\\025\\000\\000\\200?0\\001\\010\\200\\001\\020\\200\\001\"\n  }\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__SsdAnchorsCalculator\"\n  calculator: \"SsdAnchorsCalculator\"\n  output_side_packet: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__anchors\"\n  node_options {\n    type_url: \"type.googleapis.com/mediapipe.SsdAnchorsCalculatorOptions\"\n    value: \"\\035\\000\\000\\030>%\\000\\000@?-\\000\\000\\000?5\\000\\000\\000?]\\000\\000\\200?p\\001\\010\\200\\001\\020\\200\\0018\\004P\\010P\\020P\\020P\\020m\\000\\000\\200?\"\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__switchcontainer__SwitchDemuxCalculator\"\n  calculator: \"SwitchDemuxCalculator\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    [mediapipe.SwitchContainerOptions.ext] {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__switchcontainer__ConstantSidePacketCalculator_1\"\n  calculator: \"ConstantSidePacketCalculator\"\n  output_side_packet: \"PACKET:facelandmarkcpu__facelandmarksmodelloader__switchcontainer__c0__facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  options {\n    [mediapipe.ConstantSidePacketCalculatorOptions.ext] {\n      packet {\n        string_value: \"mediapipe/modules/face_landmark/face_landmark.tflite\"\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__switchcontainer__ConstantSidePacketCalculator_2\"\n  calculator: \"ConstantSidePacketCalculator\"\n  output_side_packet: \"PACKET:facelandmarkcpu__facelandmarksmodelloader__switchcontainer__c1__facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  options {\n    [mediapipe.ConstantSidePacketCalculatorOptions.ext] {\n      packet {\n        string_value: \"mediapipe/modules/face_landmark/face_landmark_with_attention.tflite\"\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__switchcontainer__SwitchMuxCalculator\"\n  calculator: \"SwitchMuxCalculator\"\n  input_side_packet: \"ENABLE:with_attention\"\n  input_side_packet: \"C0__PACKET:facelandmarkcpu__facelandmarksmodelloader__switchcontainer__c0__facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  input_side_packet: \"C1__PACKET:facelandmarkcpu__facelandmarksmodelloader__switchcontainer__c1__facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  output_side_packet: \"PACKET:facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  options {\n    [mediapipe.SwitchContainerOptions.ext] {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__LocalFileContentsCalculator\"\n  calculator: \"LocalFileContentsCalculator\"\n  input_side_packet: \"FILE_PATH:facelandmarkcpu__facelandmarksmodelloader__model_path\"\n  output_side_packet: \"CONTENTS:facelandmarkcpu__facelandmarksmodelloader__model_blob\"\n}\nnode {\n  name: \"facelandmarkcpu__facelandmarksmodelloader__TfLiteModelCalculator\"\n  calculator: \"TfLiteModelCalculator\"\n  input_side_packet: \"MODEL_BLOB:facelandmarkcpu__facelandmarksmodelloader__model_blob\"\n  output_side_packet: \"MODEL:facelandmarkcpu__model\"\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__inferencecalculator__facedetectionshortrangecpu__facedetectionshortrange__facedetection__InferenceCalculator\"\n  calculator: \"InferenceCalculatorCpu\"\n  input_stream: \"TENSORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__input_tensors\"\n  output_stream: \"TENSORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__detection_tensors\"\n  node_options {\n    type_url: \"type.googleapis.com/mediapipe.InferenceCalculatorOptions\"\n    value: \"*\\002\"\\000\\nBmediapipe/modules/face_detection/face_detection_short_range.tflite\"\n  }\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__TensorsToDetectionsCalculator\"\n  calculator: \"TensorsToDetectionsCalculator\"\n  input_stream: \"TENSORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__detection_tensors\"\n  output_stream: \"DETECTIONS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__unfiltered_detections\"\n  input_side_packet: \"ANCHORS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__anchors\"\n  node_options {\n    type_url: \"type.googleapis.com/mediapipe.TensorsToDetectionsCalculatorOptions\"\n    value: \"\\010\\001\\020\\200\\007\\030\\020%\\000\\000\\000C-\\000\\000\\000C5\\000\\000\\000C=\\000\\000\\000CH\\004P\\006X\\002`\\000p\\001x\\001\\205\\001\\000\\000\\310B\\235\\001\\000\\000\\000?\"\n  }\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__NonMaxSuppressionCalculator\"\n  calculator: \"NonMaxSuppressionCalculator\"\n  input_stream: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__unfiltered_detections\"\n  output_stream: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__filtered_detections\"\n  options {\n    [mediapipe.NonMaxSuppressionCalculatorOptions.ext] {\n      min_suppression_threshold: 0.3\n      overlap_type: INTERSECTION_OVER_UNION\n      algorithm: WEIGHTED\n    }\n  }\n}\nnode {\n  name: \"facedetectionshortrangecpu__facedetectionshortrange__facedetection__DetectionProjectionCalculator\"\n  calculator: \"DetectionProjectionCalculator\"\n  input_stream: \"DETECTIONS:facedetectionshortrangecpu__facedetectionshortrange__facedetection__filtered_detections\"\n  input_stream: \"PROJECTION_MATRIX:facedetectionshortrangecpu__facedetectionshortrange__facedetection__transform_matrix\"\n  output_stream: \"DETECTIONS:all_face_detections\"\n}\nnode {\n  calculator: \"ClipDetectionVectorSizeCalculator\"\n  input_stream: \"all_face_detections\"\n  output_stream: \"face_detections\"\n  input_side_packet: \"num_faces\"\n}\nnode {\n  calculator: \"BeginLoopDetectionCalculator\"\n  input_stream: \"ITERABLE:face_detections\"\n  input_stream: \"CLONE:gated_image_size\"\n  output_stream: \"ITEM:face_detection\"\n  output_stream: \"CLONE:detections_loop_image_size\"\n  output_stream: \"BATCH_END:detections_loop_end_timestamp\"\n}\nnode {\n  name: \"facedetectionfrontdetectiontoroi__DetectionsToRectsCalculator\"\n  calculator: \"DetectionsToRectsCalculator\"\n  input_stream: \"DETECTION:face_detection\"\n  input_stream: \"IMAGE_SIZE:detections_loop_image_size\"\n  output_stream: \"NORM_RECT:facedetectionfrontdetectiontoroi__initial_roi\"\n  options {\n    [mediapipe.DetectionsToRectsCalculatorOptions.ext] {\n      rotation_vector_start_keypoint_index: 0\n      rotation_vector_end_keypoint_index: 1\n      rotation_vector_target_angle_degrees: 0\n    }\n  }\n}\nnode {\n  name: \"facedetectionfrontdetectiontoroi__RectTransformationCalculator\"\n  calculator: \"RectTransformationCalculator\"\n  input_stream: \"NORM_RECT:facedetectionfrontdetectiontoroi__initial_roi\"\n  input_stream: \"IMAGE_SIZE:detections_loop_image_size\"\n  output_stream: \"face_rect_from_detection\"\n  options {\n    [mediapipe.RectTransformationCalculatorOptions.ext] {\n      scale_x: 1.5\n      scale_y: 1.5\n      square_long: true\n    }\n  }\n}\nnode {\n  calculator: \"EndLoopNormalizedRectCalculator\"\n  input_stream: \"ITEM:face_rect_from_detection\"\n  input_stream: \"BATCH_END:detections_loop_end_timestamp\"\n  output_stream: \"ITERABLE:face_rects_from_detections\"\n}\nnode {\n  calculator: \"AssociationNormRectCalculator\"\n  input_stream: \"face_rects_from_detections\"\n  input_stream: \"gated_prev_face_rects_from_landmarks\"\n  output_stream: \"face_rects\"\n  options {\n    [mediapipe.AssociationCalculatorOptions.ext] {\n      min_similarity_threshold: 0.5\n    }\n  }\n}\nnode {\n  calculator: \"BeginLoopNormalizedRectCalculator\"\n  input_stream: \"ITERABLE:face_rects\"\n  input_stream: \"CLONE:0:image\"\n  input_stream: \"CLONE:1:image_size\"\n  output_stream: \"ITEM:face_rect\"\n  output_stream: \"CLONE:0:landmarks_loop_image\"\n  output_stream: \"CLONE:1:landmarks_loop_image_size\"\n  output_stream: \"BATCH_END:landmarks_loop_end_timestamp\"\n}\nnode {\n  name: \"facelandmarkcpu__ImageToTensorCalculator\"\n  calculator: \"ImageToTensorCalculator\"\n  input_stream: \"IMAGE:landmarks_loop_image\"\n  input_stream: \"NORM_RECT:face_rect\"\n  output_stream: \"TENSORS:facelandmarkcpu__input_tensors\"\n  options {\n    [mediapipe.ImageToTensorCalculatorOptions.ext] {\n      output_tensor_width: 192\n      output_tensor_height: 192\n      output_tensor_float_range {\n        min: 0\n        max: 1\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__inferencecalculator__facelandmarkcpu__InferenceCalculator\"\n  calculator: \"InferenceCalculatorCpu\"\n  input_stream: \"TENSORS:facelandmarkcpu__input_tensors\"\n  output_stream: \"TENSORS:facelandmarkcpu__output_tensors\"\n  input_side_packet: \"MODEL:facelandmarkcpu__model\"\n  input_side_packet: \"OP_RESOLVER:facelandmarkcpu__op_resolver\"\n  options {\n    [mediapipe.InferenceCalculatorOptions.ext] {\n      delegate {\n        xnnpack {\n        }\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_1__SwitchDemuxCalculator\"\n  calculator: \"SwitchDemuxCalculator\"\n  input_stream: \"facelandmarkcpu__output_tensors\"\n  output_stream: \"C0__:facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__output_tensors\"\n  output_stream: \"C1__:facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__output_tensors\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    [mediapipe.SwitchContainerOptions.ext] {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_1__SplitTensorVectorCalculator_1\"\n  calculator: \"SplitTensorVectorCalculator\"\n  input_stream: \"facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__output_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__landmark_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__face_flag_tensor\"\n  options {\n    [mediapipe.SplitVectorCalculatorOptions.ext] {\n      ranges {\n        begin: 0\n        end: 1\n      }\n      ranges {\n        begin: 1\n        end: 2\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_1__SplitTensorVectorCalculator_2\"\n  calculator: \"SplitTensorVectorCalculator\"\n  input_stream: \"facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__output_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__landmark_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__face_flag_tensor\"\n  options {\n    [mediapipe.SplitVectorCalculatorOptions.ext] {\n      ranges {\n        begin: 0\n        end: 6\n      }\n      ranges {\n        begin: 6\n        end: 7\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_1__SwitchMuxCalculator\"\n  calculator: \"SwitchMuxCalculator\"\n  input_stream: \"C0__:facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__landmark_tensors\"\n  input_stream: \"C0__:1:facelandmarkcpu__switchcontainer_1__c0__facelandmarkcpu__face_flag_tensor\"\n  input_stream: \"C1__:facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__landmark_tensors\"\n  input_stream: \"C1__:1:facelandmarkcpu__switchcontainer_1__c1__facelandmarkcpu__face_flag_tensor\"\n  output_stream: \"facelandmarkcpu__landmark_tensors\"\n  output_stream: \"facelandmarkcpu__face_flag_tensor\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    [mediapipe.SwitchContainerOptions.ext] {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__TensorsToFloatsCalculator\"\n  calculator: \"TensorsToFloatsCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__face_flag_tensor\"\n  output_stream: \"FLOAT:facelandmarkcpu__face_presence_score\"\n  options {\n    [mediapipe.TensorsToFloatsCalculatorOptions.ext] {\n      activation: SIGMOID\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__ThresholdingCalculator\"\n  calculator: \"ThresholdingCalculator\"\n  input_stream: \"FLOAT:facelandmarkcpu__face_presence_score\"\n  output_stream: \"FLAG:facelandmarkcpu__face_presence\"\n  options {\n    [mediapipe.ThresholdingCalculatorOptions.ext] {\n      threshold: 0.5\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__GateCalculator\"\n  calculator: \"GateCalculator\"\n  input_stream: \"facelandmarkcpu__landmark_tensors\"\n  input_stream: \"ALLOW:facelandmarkcpu__face_presence\"\n  output_stream: \"facelandmarkcpu__ensured_landmark_tensors\"\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__SwitchDemuxCalculator\"\n  calculator: \"SwitchDemuxCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__ensured_landmark_tensors\"\n  output_stream: \"C0__TENSORS:facelandmarkcpu__switchcontainer_2__c0__facelandmarkcpu__ensured_landmark_tensors\"\n  output_stream: \"C1__TENSORS:facelandmarkcpu__switchcontainer_2__c1__facelandmarkcpu__ensured_landmark_tensors\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    [mediapipe.SwitchContainerOptions.ext] {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarks__TensorsToLandmarksCalculator\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__c0__facelandmarkcpu__ensured_landmark_tensors\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__c0__facelandmarkcpu__landmarks\"\n  options {\n    [mediapipe.TensorsToLandmarksCalculatorOptions.ext] {\n      num_landmarks: 468\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__SplitTensorVectorCalculator\"\n  calculator: \"SplitTensorVectorCalculator\"\n  input_stream: \"facelandmarkcpu__switchcontainer_2__c1__facelandmarkcpu__ensured_landmark_tensors\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__mesh_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__lips_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_eye_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_eye_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_iris_tensor\"\n  output_stream: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_iris_tensor\"\n  options {\n    [mediapipe.SplitVectorCalculatorOptions.ext] {\n      ranges {\n        begin: 0\n        end: 1\n      }\n      ranges {\n        begin: 1\n        end: 2\n      }\n      ranges {\n        begin: 2\n        end: 3\n      }\n      ranges {\n        begin: 3\n        end: 4\n      }\n      ranges {\n        begin: 4\n        end: 5\n      }\n      ranges {\n        begin: 5\n        end: 6\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_1\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__mesh_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__mesh_landmarks\"\n  options {\n    [mediapipe.TensorsToLandmarksCalculatorOptions.ext] {\n      num_landmarks: 468\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_2\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__lips_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__lips_landmarks\"\n  options {\n    [mediapipe.TensorsToLandmarksCalculatorOptions.ext] {\n      num_landmarks: 80\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_3\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_eye_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_eye_landmarks\"\n  options {\n    [mediapipe.TensorsToLandmarksCalculatorOptions.ext] {\n      num_landmarks: 71\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_4\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_eye_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_eye_landmarks\"\n  options {\n    [mediapipe.TensorsToLandmarksCalculatorOptions.ext] {\n      num_landmarks: 71\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_5\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_iris_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_iris_landmarks\"\n  options {\n    [mediapipe.TensorsToLandmarksCalculatorOptions.ext] {\n      num_landmarks: 5\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__TensorsToLandmarksCalculator_6\"\n  calculator: \"TensorsToLandmarksCalculator\"\n  input_stream: \"TENSORS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_iris_tensor\"\n  output_stream: \"NORM_LANDMARKS:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_iris_landmarks\"\n  options {\n    [mediapipe.TensorsToLandmarksCalculatorOptions.ext] {\n      num_landmarks: 5\n      input_image_width: 192\n      input_image_height: 192\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__LandmarksRefinementCalculator\"\n  calculator: \"LandmarksRefinementCalculator\"\n  input_stream: \"LANDMARKS:0:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__mesh_landmarks\"\n  input_stream: \"LANDMARKS:1:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__lips_landmarks\"\n  input_stream: \"LANDMARKS:2:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_eye_landmarks\"\n  input_stream: \"LANDMARKS:3:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_eye_landmarks\"\n  input_stream: \"LANDMARKS:4:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__left_iris_landmarks\"\n  input_stream: \"LANDMARKS:5:facelandmarkcpu__switchcontainer_2__tensorstofacelandmarkswithattention__right_iris_landmarks\"\n  output_stream: \"REFINED_LANDMARKS:facelandmarkcpu__switchcontainer_2__c1__facelandmarkcpu__landmarks\"\n  options {\n    [mediapipe.LandmarksRefinementCalculatorOptions.ext] {\n      refinement {\n        indexes_mapping: 0\n        indexes_mapping: 1\n        indexes_mapping: 2\n        indexes_mapping: 3\n        indexes_mapping: 4\n        indexes_mapping: 5\n        indexes_mapping: 6\n        indexes_mapping: 7\n        indexes_mapping: 8\n        indexes_mapping: 9\n        indexes_mapping: 10\n        indexes_mapping: 11\n        indexes_mapping: 12\n        indexes_mapping: 13\n        indexes_mapping: 14\n        indexes_mapping: 15\n        indexes_mapping: 16\n        indexes_mapping: 17\n        indexes_mapping: 18\n        indexes_mapping: 19\n        indexes_mapping: 20\n        indexes_mapping: 21\n        indexes_mapping: 22\n        indexes_mapping: 23\n        indexes_mapping: 24\n        indexes_mapping: 25\n        indexes_mapping: 26\n        indexes_mapping: 27\n        indexes_mapping: 28\n        indexes_mapping: 29\n        indexes_mapping: 30\n        indexes_mapping: 31\n        indexes_mapping: 32\n        indexes_mapping: 33\n        indexes_mapping: 34\n        indexes_mapping: 35\n        indexes_mapping: 36\n        indexes_mapping: 37\n        indexes_mapping: 38\n        indexes_mapping: 39\n        indexes_mapping: 40\n        indexes_mapping: 41\n        indexes_mapping: 42\n        indexes_mapping: 43\n        indexes_mapping: 44\n        indexes_mapping: 45\n        indexes_mapping: 46\n        indexes_mapping: 47\n        indexes_mapping: 48\n        indexes_mapping: 49\n        indexes_mapping: 50\n        indexes_mapping: 51\n        indexes_mapping: 52\n        indexes_mapping: 53\n        indexes_mapping: 54\n        indexes_mapping: 55\n        indexes_mapping: 56\n        indexes_mapping: 57\n        indexes_mapping: 58\n        indexes_mapping: 59\n        indexes_mapping: 60\n        indexes_mapping: 61\n        indexes_mapping: 62\n        indexes_mapping: 63\n        indexes_mapping: 64\n        indexes_mapping: 65\n        indexes_mapping: 66\n        indexes_mapping: 67\n        indexes_mapping: 68\n        indexes_mapping: 69\n        indexes_mapping: 70\n        indexes_mapping: 71\n        indexes_mapping: 72\n        indexes_mapping: 73\n        indexes_mapping: 74\n        indexes_mapping: 75\n        indexes_mapping: 76\n        indexes_mapping: 77\n        indexes_mapping: 78\n        indexes_mapping: 79\n        indexes_mapping: 80\n        indexes_mapping: 81\n        indexes_mapping: 82\n        indexes_mapping: 83\n        indexes_mapping: 84\n        indexes_mapping: 85\n        indexes_mapping: 86\n        indexes_mapping: 87\n        indexes_mapping: 88\n        indexes_mapping: 89\n        indexes_mapping: 90\n        indexes_mapping: 91\n        indexes_mapping: 92\n        indexes_mapping: 93\n        indexes_mapping: 94\n        indexes_mapping: 95\n        indexes_mapping: 96\n        indexes_mapping: 97\n        indexes_mapping: 98\n        indexes_mapping: 99\n        indexes_mapping: 100\n        indexes_mapping: 101\n        indexes_mapping: 102\n        indexes_mapping: 103\n        indexes_mapping: 104\n        indexes_mapping: 105\n        indexes_mapping: 106\n        indexes_mapping: 107\n        indexes_mapping: 108\n        indexes_mapping: 109\n        indexes_mapping: 110\n        indexes_mapping: 111\n        indexes_mapping: 112\n        indexes_mapping: 113\n        indexes_mapping: 114\n        indexes_mapping: 115\n        indexes_mapping: 116\n        indexes_mapping: 117\n        indexes_mapping: 118\n        indexes_mapping: 119\n        indexes_mapping: 120\n        indexes_mapping: 121\n        indexes_mapping: 122\n        indexes_mapping: 123\n        indexes_mapping: 124\n        indexes_mapping: 125\n        indexes_mapping: 126\n        indexes_mapping: 127\n        indexes_mapping: 128\n        indexes_mapping: 129\n        indexes_mapping: 130\n        indexes_mapping: 131\n        indexes_mapping: 132\n        indexes_mapping: 133\n        indexes_mapping: 134\n        indexes_mapping: 135\n        indexes_mapping: 136\n        indexes_mapping: 137\n        indexes_mapping: 138\n        indexes_mapping: 139\n        indexes_mapping: 140\n        indexes_mapping: 141\n        indexes_mapping: 142\n        indexes_mapping: 143\n        indexes_mapping: 144\n        indexes_mapping: 145\n        indexes_mapping: 146\n        indexes_mapping: 147\n        indexes_mapping: 148\n        indexes_mapping: 149\n        indexes_mapping: 150\n        indexes_mapping: 151\n        indexes_mapping: 152\n        indexes_mapping: 153\n        indexes_mapping: 154\n        indexes_mapping: 155\n        indexes_mapping: 156\n        indexes_mapping: 157\n        indexes_mapping: 158\n        indexes_mapping: 159\n        indexes_mapping: 160\n        indexes_mapping: 161\n        indexes_mapping: 162\n        indexes_mapping: 163\n        indexes_mapping: 164\n        indexes_mapping: 165\n        indexes_mapping: 166\n        indexes_mapping: 167\n        indexes_mapping: 168\n        indexes_mapping: 169\n        indexes_mapping: 170\n        indexes_mapping: 171\n        indexes_mapping: 172\n        indexes_mapping: 173\n        indexes_mapping: 174\n        indexes_mapping: 175\n        indexes_mapping: 176\n        indexes_mapping: 177\n        indexes_mapping: 178\n        indexes_mapping: 179\n        indexes_mapping: 180\n        indexes_mapping: 181\n        indexes_mapping: 182\n        indexes_mapping: 183\n        indexes_mapping: 184\n        indexes_mapping: 185\n        indexes_mapping: 186\n        indexes_mapping: 187\n        indexes_mapping: 188\n        indexes_mapping: 189\n        indexes_mapping: 190\n        indexes_mapping: 191\n        indexes_mapping: 192\n        indexes_mapping: 193\n        indexes_mapping: 194\n        indexes_mapping: 195\n        indexes_mapping: 196\n        indexes_mapping: 197\n        indexes_mapping: 198\n        indexes_mapping: 199\n        indexes_mapping: 200\n        indexes_mapping: 201\n        indexes_mapping: 202\n        indexes_mapping: 203\n        indexes_mapping: 204\n        indexes_mapping: 205\n        indexes_mapping: 206\n        indexes_mapping: 207\n        indexes_mapping: 208\n        indexes_mapping: 209\n        indexes_mapping: 210\n        indexes_mapping: 211\n        indexes_mapping: 212\n        indexes_mapping: 213\n        indexes_mapping: 214\n        indexes_mapping: 215\n        indexes_mapping: 216\n        indexes_mapping: 217\n        indexes_mapping: 218\n        indexes_mapping: 219\n        indexes_mapping: 220\n        indexes_mapping: 221\n        indexes_mapping: 222\n        indexes_mapping: 223\n        indexes_mapping: 224\n        indexes_mapping: 225\n        indexes_mapping: 226\n        indexes_mapping: 227\n        indexes_mapping: 228\n        indexes_mapping: 229\n        indexes_mapping: 230\n        indexes_mapping: 231\n        indexes_mapping: 232\n        indexes_mapping: 233\n        indexes_mapping: 234\n        indexes_mapping: 235\n        indexes_mapping: 236\n        indexes_mapping: 237\n        indexes_mapping: 238\n        indexes_mapping: 239\n        indexes_mapping: 240\n        indexes_mapping: 241\n        indexes_mapping: 242\n        indexes_mapping: 243\n        indexes_mapping: 244\n        indexes_mapping: 245\n        indexes_mapping: 246\n        indexes_mapping: 247\n        indexes_mapping: 248\n        indexes_mapping: 249\n        indexes_mapping: 250\n        indexes_mapping: 251\n        indexes_mapping: 252\n        indexes_mapping: 253\n        indexes_mapping: 254\n        indexes_mapping: 255\n        indexes_mapping: 256\n        indexes_mapping: 257\n        indexes_mapping: 258\n        indexes_mapping: 259\n        indexes_mapping: 260\n        indexes_mapping: 261\n        indexes_mapping: 262\n        indexes_mapping: 263\n        indexes_mapping: 264\n        indexes_mapping: 265\n        indexes_mapping: 266\n        indexes_mapping: 267\n        indexes_mapping: 268\n        indexes_mapping: 269\n        indexes_mapping: 270\n        indexes_mapping: 271\n        indexes_mapping: 272\n        indexes_mapping: 273\n        indexes_mapping: 274\n        indexes_mapping: 275\n        indexes_mapping: 276\n        indexes_mapping: 277\n        indexes_mapping: 278\n        indexes_mapping: 279\n        indexes_mapping: 280\n        indexes_mapping: 281\n        indexes_mapping: 282\n        indexes_mapping: 283\n        indexes_mapping: 284\n        indexes_mapping: 285\n        indexes_mapping: 286\n        indexes_mapping: 287\n        indexes_mapping: 288\n        indexes_mapping: 289\n        indexes_mapping: 290\n        indexes_mapping: 291\n        indexes_mapping: 292\n        indexes_mapping: 293\n        indexes_mapping: 294\n        indexes_mapping: 295\n        indexes_mapping: 296\n        indexes_mapping: 297\n        indexes_mapping: 298\n        indexes_mapping: 299\n        indexes_mapping: 300\n        indexes_mapping: 301\n        indexes_mapping: 302\n        indexes_mapping: 303\n        indexes_mapping: 304\n        indexes_mapping: 305\n        indexes_mapping: 306\n        indexes_mapping: 307\n        indexes_mapping: 308\n        indexes_mapping: 309\n        indexes_mapping: 310\n        indexes_mapping: 311\n        indexes_mapping: 312\n        indexes_mapping: 313\n        indexes_mapping: 314\n        indexes_mapping: 315\n        indexes_mapping: 316\n        indexes_mapping: 317\n        indexes_mapping: 318\n        indexes_mapping: 319\n        indexes_mapping: 320\n        indexes_mapping: 321\n        indexes_mapping: 322\n        indexes_mapping: 323\n        indexes_mapping: 324\n        indexes_mapping: 325\n        indexes_mapping: 326\n        indexes_mapping: 327\n        indexes_mapping: 328\n        indexes_mapping: 329\n        indexes_mapping: 330\n        indexes_mapping: 331\n        indexes_mapping: 332\n        indexes_mapping: 333\n        indexes_mapping: 334\n        indexes_mapping: 335\n        indexes_mapping: 336\n        indexes_mapping: 337\n        indexes_mapping: 338\n        indexes_mapping: 339\n        indexes_mapping: 340\n        indexes_mapping: 341\n        indexes_mapping: 342\n        indexes_mapping: 343\n        indexes_mapping: 344\n        indexes_mapping: 345\n        indexes_mapping: 346\n        indexes_mapping: 347\n        indexes_mapping: 348\n        indexes_mapping: 349\n        indexes_mapping: 350\n        indexes_mapping: 351\n        indexes_mapping: 352\n        indexes_mapping: 353\n        indexes_mapping: 354\n        indexes_mapping: 355\n        indexes_mapping: 356\n        indexes_mapping: 357\n        indexes_mapping: 358\n        indexes_mapping: 359\n        indexes_mapping: 360\n        indexes_mapping: 361\n        indexes_mapping: 362\n        indexes_mapping: 363\n        indexes_mapping: 364\n        indexes_mapping: 365\n        indexes_mapping: 366\n        indexes_mapping: 367\n        indexes_mapping: 368\n        indexes_mapping: 369\n        indexes_mapping: 370\n        indexes_mapping: 371\n        indexes_mapping: 372\n        indexes_mapping: 373\n        indexes_mapping: 374\n        indexes_mapping: 375\n        indexes_mapping: 376\n        indexes_mapping: 377\n        indexes_mapping: 378\n        indexes_mapping: 379\n        indexes_mapping: 380\n        indexes_mapping: 381\n        indexes_mapping: 382\n        indexes_mapping: 383\n        indexes_mapping: 384\n        indexes_mapping: 385\n        indexes_mapping: 386\n        indexes_mapping: 387\n        indexes_mapping: 388\n        indexes_mapping: 389\n        indexes_mapping: 390\n        indexes_mapping: 391\n        indexes_mapping: 392\n        indexes_mapping: 393\n        indexes_mapping: 394\n        indexes_mapping: 395\n        indexes_mapping: 396\n        indexes_mapping: 397\n        indexes_mapping: 398\n        indexes_mapping: 399\n        indexes_mapping: 400\n        indexes_mapping: 401\n        indexes_mapping: 402\n        indexes_mapping: 403\n        indexes_mapping: 404\n        indexes_mapping: 405\n        indexes_mapping: 406\n        indexes_mapping: 407\n        indexes_mapping: 408\n        indexes_mapping: 409\n        indexes_mapping: 410\n        indexes_mapping: 411\n        indexes_mapping: 412\n        indexes_mapping: 413\n        indexes_mapping: 414\n        indexes_mapping: 415\n        indexes_mapping: 416\n        indexes_mapping: 417\n        indexes_mapping: 418\n        indexes_mapping: 419\n        indexes_mapping: 420\n        indexes_mapping: 421\n        indexes_mapping: 422\n        indexes_mapping: 423\n        indexes_mapping: 424\n        indexes_mapping: 425\n        indexes_mapping: 426\n        indexes_mapping: 427\n        indexes_mapping: 428\n        indexes_mapping: 429\n        indexes_mapping: 430\n        indexes_mapping: 431\n        indexes_mapping: 432\n        indexes_mapping: 433\n        indexes_mapping: 434\n        indexes_mapping: 435\n        indexes_mapping: 436\n        indexes_mapping: 437\n        indexes_mapping: 438\n        indexes_mapping: 439\n        indexes_mapping: 440\n        indexes_mapping: 441\n        indexes_mapping: 442\n        indexes_mapping: 443\n        indexes_mapping: 444\n        indexes_mapping: 445\n        indexes_mapping: 446\n        indexes_mapping: 447\n        indexes_mapping: 448\n        indexes_mapping: 449\n        indexes_mapping: 450\n        indexes_mapping: 451\n        indexes_mapping: 452\n        indexes_mapping: 453\n        indexes_mapping: 454\n        indexes_mapping: 455\n        indexes_mapping: 456\n        indexes_mapping: 457\n        indexes_mapping: 458\n        indexes_mapping: 459\n        indexes_mapping: 460\n        indexes_mapping: 461\n        indexes_mapping: 462\n        indexes_mapping: 463\n        indexes_mapping: 464\n        indexes_mapping: 465\n        indexes_mapping: 466\n        indexes_mapping: 467\n        z_refinement {\n          copy {\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 61\n        indexes_mapping: 146\n        indexes_mapping: 91\n        indexes_mapping: 181\n        indexes_mapping: 84\n        indexes_mapping: 17\n        indexes_mapping: 314\n        indexes_mapping: 405\n        indexes_mapping: 321\n        indexes_mapping: 375\n        indexes_mapping: 291\n        indexes_mapping: 185\n        indexes_mapping: 40\n        indexes_mapping: 39\n        indexes_mapping: 37\n        indexes_mapping: 0\n        indexes_mapping: 267\n        indexes_mapping: 269\n        indexes_mapping: 270\n        indexes_mapping: 409\n        indexes_mapping: 78\n        indexes_mapping: 95\n        indexes_mapping: 88\n        indexes_mapping: 178\n        indexes_mapping: 87\n        indexes_mapping: 14\n        indexes_mapping: 317\n        indexes_mapping: 402\n        indexes_mapping: 318\n        indexes_mapping: 324\n        indexes_mapping: 308\n        indexes_mapping: 191\n        indexes_mapping: 80\n        indexes_mapping: 81\n        indexes_mapping: 82\n        indexes_mapping: 13\n        indexes_mapping: 312\n        indexes_mapping: 311\n        indexes_mapping: 310\n        indexes_mapping: 415\n        indexes_mapping: 76\n        indexes_mapping: 77\n        indexes_mapping: 90\n        indexes_mapping: 180\n        indexes_mapping: 85\n        indexes_mapping: 16\n        indexes_mapping: 315\n        indexes_mapping: 404\n        indexes_mapping: 320\n        indexes_mapping: 307\n        indexes_mapping: 306\n        indexes_mapping: 184\n        indexes_mapping: 74\n        indexes_mapping: 73\n        indexes_mapping: 72\n        indexes_mapping: 11\n        indexes_mapping: 302\n        indexes_mapping: 303\n        indexes_mapping: 304\n        indexes_mapping: 408\n        indexes_mapping: 62\n        indexes_mapping: 96\n        indexes_mapping: 89\n        indexes_mapping: 179\n        indexes_mapping: 86\n        indexes_mapping: 15\n        indexes_mapping: 316\n        indexes_mapping: 403\n        indexes_mapping: 319\n        indexes_mapping: 325\n        indexes_mapping: 292\n        indexes_mapping: 183\n        indexes_mapping: 42\n        indexes_mapping: 41\n        indexes_mapping: 38\n        indexes_mapping: 12\n        indexes_mapping: 268\n        indexes_mapping: 271\n        indexes_mapping: 272\n        indexes_mapping: 407\n        z_refinement {\n          none {\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 33\n        indexes_mapping: 7\n        indexes_mapping: 163\n        indexes_mapping: 144\n        indexes_mapping: 145\n        indexes_mapping: 153\n        indexes_mapping: 154\n        indexes_mapping: 155\n        indexes_mapping: 133\n        indexes_mapping: 246\n        indexes_mapping: 161\n        indexes_mapping: 160\n        indexes_mapping: 159\n        indexes_mapping: 158\n        indexes_mapping: 157\n        indexes_mapping: 173\n        indexes_mapping: 130\n        indexes_mapping: 25\n        indexes_mapping: 110\n        indexes_mapping: 24\n        indexes_mapping: 23\n        indexes_mapping: 22\n        indexes_mapping: 26\n        indexes_mapping: 112\n        indexes_mapping: 243\n        indexes_mapping: 247\n        indexes_mapping: 30\n        indexes_mapping: 29\n        indexes_mapping: 27\n        indexes_mapping: 28\n        indexes_mapping: 56\n        indexes_mapping: 190\n        indexes_mapping: 226\n        indexes_mapping: 31\n        indexes_mapping: 228\n        indexes_mapping: 229\n        indexes_mapping: 230\n        indexes_mapping: 231\n        indexes_mapping: 232\n        indexes_mapping: 233\n        indexes_mapping: 244\n        indexes_mapping: 113\n        indexes_mapping: 225\n        indexes_mapping: 224\n        indexes_mapping: 223\n        indexes_mapping: 222\n        indexes_mapping: 221\n        indexes_mapping: 189\n        indexes_mapping: 35\n        indexes_mapping: 124\n        indexes_mapping: 46\n        indexes_mapping: 53\n        indexes_mapping: 52\n        indexes_mapping: 65\n        indexes_mapping: 143\n        indexes_mapping: 111\n        indexes_mapping: 117\n        indexes_mapping: 118\n        indexes_mapping: 119\n        indexes_mapping: 120\n        indexes_mapping: 121\n        indexes_mapping: 128\n        indexes_mapping: 245\n        indexes_mapping: 156\n        indexes_mapping: 70\n        indexes_mapping: 63\n        indexes_mapping: 105\n        indexes_mapping: 66\n        indexes_mapping: 107\n        indexes_mapping: 55\n        indexes_mapping: 193\n        z_refinement {\n          none {\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 263\n        indexes_mapping: 249\n        indexes_mapping: 390\n        indexes_mapping: 373\n        indexes_mapping: 374\n        indexes_mapping: 380\n        indexes_mapping: 381\n        indexes_mapping: 382\n        indexes_mapping: 362\n        indexes_mapping: 466\n        indexes_mapping: 388\n        indexes_mapping: 387\n        indexes_mapping: 386\n        indexes_mapping: 385\n        indexes_mapping: 384\n        indexes_mapping: 398\n        indexes_mapping: 359\n        indexes_mapping: 255\n        indexes_mapping: 339\n        indexes_mapping: 254\n        indexes_mapping: 253\n        indexes_mapping: 252\n        indexes_mapping: 256\n        indexes_mapping: 341\n        indexes_mapping: 463\n        indexes_mapping: 467\n        indexes_mapping: 260\n        indexes_mapping: 259\n        indexes_mapping: 257\n        indexes_mapping: 258\n        indexes_mapping: 286\n        indexes_mapping: 414\n        indexes_mapping: 446\n        indexes_mapping: 261\n        indexes_mapping: 448\n        indexes_mapping: 449\n        indexes_mapping: 450\n        indexes_mapping: 451\n        indexes_mapping: 452\n        indexes_mapping: 453\n        indexes_mapping: 464\n        indexes_mapping: 342\n        indexes_mapping: 445\n        indexes_mapping: 444\n        indexes_mapping: 443\n        indexes_mapping: 442\n        indexes_mapping: 441\n        indexes_mapping: 413\n        indexes_mapping: 265\n        indexes_mapping: 353\n        indexes_mapping: 276\n        indexes_mapping: 283\n        indexes_mapping: 282\n        indexes_mapping: 295\n        indexes_mapping: 372\n        indexes_mapping: 340\n        indexes_mapping: 346\n        indexes_mapping: 347\n        indexes_mapping: 348\n        indexes_mapping: 349\n        indexes_mapping: 350\n        indexes_mapping: 357\n        indexes_mapping: 465\n        indexes_mapping: 383\n        indexes_mapping: 300\n        indexes_mapping: 293\n        indexes_mapping: 334\n        indexes_mapping: 296\n        indexes_mapping: 336\n        indexes_mapping: 285\n        indexes_mapping: 417\n        z_refinement {\n          none {\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 468\n        indexes_mapping: 469\n        indexes_mapping: 470\n        indexes_mapping: 471\n        indexes_mapping: 472\n        z_refinement {\n          assign_average {\n            indexes_for_average: 33\n            indexes_for_average: 7\n            indexes_for_average: 163\n            indexes_for_average: 144\n            indexes_for_average: 145\n            indexes_for_average: 153\n            indexes_for_average: 154\n            indexes_for_average: 155\n            indexes_for_average: 133\n            indexes_for_average: 246\n            indexes_for_average: 161\n            indexes_for_average: 160\n            indexes_for_average: 159\n            indexes_for_average: 158\n            indexes_for_average: 157\n            indexes_for_average: 173\n          }\n        }\n      }\n      refinement {\n        indexes_mapping: 473\n        indexes_mapping: 474\n        indexes_mapping: 475\n        indexes_mapping: 476\n        indexes_mapping: 477\n        z_refinement {\n          assign_average {\n            indexes_for_average: 263\n            indexes_for_average: 249\n            indexes_for_average: 390\n            indexes_for_average: 373\n            indexes_for_average: 374\n            indexes_for_average: 380\n            indexes_for_average: 381\n            indexes_for_average: 382\n            indexes_for_average: 362\n            indexes_for_average: 466\n            indexes_for_average: 388\n            indexes_for_average: 387\n            indexes_for_average: 386\n            indexes_for_average: 385\n            indexes_for_average: 384\n            indexes_for_average: 398\n          }\n        }\n      }\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__switchcontainer_2__SwitchMuxCalculator\"\n  calculator: \"SwitchMuxCalculator\"\n  input_stream: \"C0__LANDMARKS:facelandmarkcpu__switchcontainer_2__c0__facelandmarkcpu__landmarks\"\n  input_stream: \"C1__LANDMARKS:facelandmarkcpu__switchcontainer_2__c1__facelandmarkcpu__landmarks\"\n  output_stream: \"LANDMARKS:facelandmarkcpu__landmarks\"\n  input_side_packet: \"ENABLE:with_attention\"\n  options {\n    [mediapipe.SwitchContainerOptions.ext] {\n    }\n  }\n}\nnode {\n  name: \"facelandmarkcpu__LandmarkProjectionCalculator\"\n  calculator: \"LandmarkProjectionCalculator\"\n  input_stream: \"NORM_LANDMARKS:facelandmarkcpu__landmarks\"\n  input_stream: \"NORM_RECT:face_rect\"\n  output_stream: \"NORM_LANDMARKS:face_landmarks\"\n}\nnode {\n  calculator: \"EndLoopNormalizedLandmarkListVectorCalculator\"\n  input_stream: \"ITEM:face_landmarks\"\n  input_stream: \"BATCH_END:landmarks_loop_end_timestamp\"\n  output_stream: \"ITERABLE:multi_face_landmarks\"\n}\nnode {\n  name: \"facelandmarklandmarkstoroi__LandmarksToDetectionCalculator\"\n  calculator: \"LandmarksToDetectionCalculator\"\n  input_stream: \"NORM_LANDMARKS:face_landmarks\"\n  output_stream: \"DETECTION:facelandmarklandmarkstoroi__face_detection\"\n}\nnode {\n  name: \"facelandmarklandmarkstoroi__DetectionsToRectsCalculator\"\n  calculator: \"DetectionsToRectsCalculator\"\n  input_stream: \"DETECTION:facelandmarklandmarkstoroi__face_detection\"\n  input_stream: \"IMAGE_SIZE:landmarks_loop_image_size\"\n  output_stream: \"NORM_RECT:facelandmarklandmarkstoroi__face_rect_from_landmarks\"\n  options {\n    [mediapipe.DetectionsToRectsCalculatorOptions.ext] {\n      rotation_vector_start_keypoint_index: 33\n      rotation_vector_end_keypoint_index: 263\n      rotation_vector_target_angle_degrees: 0\n    }\n  }\n}\nnode {\n  name: \"facelandmarklandmarkstoroi__RectTransformationCalculator\"\n  calculator: \"RectTransformationCalculator\"\n  input_stream: \"NORM_RECT:facelandmarklandmarkstoroi__face_rect_from_landmarks\"\n  input_stream: \"IMAGE_SIZE:landmarks_loop_image_size\"\n  output_stream: \"face_rect_from_landmarks\"\n  options {\n    [mediapipe.RectTransformationCalculatorOptions.ext] {\n      scale_x: 1.5\n      scale_y: 1.5\n      square_long: true\n    }\n  }\n}\nnode {\n  calculator: \"EndLoopNormalizedRectCalculator\"\n  input_stream: \"ITEM:face_rect_from_landmarks\"\n  input_stream: \"BATCH_END:landmarks_loop_end_timestamp\"\n  output_stream: \"ITERABLE:face_rects_from_landmarks\"\n}\ninput_stream: \"IMAGE:image\"\nexecutor {\n}\noutput_stream: \"LANDMARKS:multi_face_landmarks\"\noutput_stream: \"DETECTIONS:face_detections\"\noutput_stream: \"ROIS_FROM_LANDMARKS:face_rects_from_landmarks\"\noutput_stream: \"ROIS_FROM_DETECTIONS:face_rects_from_detections\"\ninput_side_packet: \"NUM_FACES:num_faces\"\ninput_side_packet: \"USE_PREV_LANDMARKS:use_prev_landmarks\"\ninput_side_packet: \"WITH_ATTENTION:with_attention\"\ntype: \"FaceLandmarkFrontCpu\"\n"
     ]
    }
   ],
   "source": [
    "# FUNCTION BASED WITH VIDEO PATH AS INPUT TO THE MAIN FUNCTION\n",
    "# WITH VIDEO UNREADBILITY ERROR HANDLING\n",
    "\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import utils, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# variables \n",
    "frame_counter =0\n",
    "CEF_COUNTER =0\n",
    "TOTAL_BLINKS =0\n",
    "looked_left_count = 0\n",
    "looked_right_count = 0\n",
    "looked_center_count = 0\n",
    "# constants\n",
    "CLOSED_EYES_FRAME =3\n",
    "FONTS =cv.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "# face bounder indices \n",
    "FACE_OVAL=[ 10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103,67, 109]\n",
    "\n",
    "# lips indices for Landmarks\n",
    "LIPS=[ 61, 146, 91, 181, 84, 17, 314, 405, 321, 375,291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95,185, 40, 39, 37,0 ,267 ,269 ,270 ,409, 415, 310, 311, 312, 13, 82, 81, 42, 183, 78 ]\n",
    "LOWER_LIPS =[61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "UPPER_LIPS=[ 185, 40, 39, 37,0 ,267 ,269 ,270 ,409, 415, 310, 311, 312, 13, 82, 81, 42, 183, 78] \n",
    "# Left eyes indices \n",
    "LEFT_EYE =[ 362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385,384, 398 ]\n",
    "LEFT_EYEBROW =[ 336, 296, 334, 293, 300, 276, 283, 282, 295, 285 ]\n",
    "\n",
    "# right eyes indices\n",
    "RIGHT_EYE=[ 33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161 , 246 ]  \n",
    "RIGHT_EYEBROW=[ 70, 63, 105, 66, 107, 55, 65, 52, 53, 46 ]\n",
    "\n",
    "map_face_mesh = mp.solutions.face_mesh\n",
    "# camera object \n",
    "#camera = cv.VideoCapture(0)\n",
    "#camera = cv.VideoCapture('C:/Users/DIACTO/Videos/Captures/2-3 min introduction video.mp4')\n",
    "\n",
    "# For each individual frames\n",
    "# columns = ['Total Blinks', 'Looked Left Count', 'Looked Right Count']\n",
    "# results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "final_results_columns = ['Frame Count', 'FPS', 'Total Blinks', 'Total Looked Left', 'Total Looked Right', 'Total Looked Center']\n",
    "final_results_df = pd.DataFrame(columns=final_results_columns)\n",
    "\n",
    "# landmark detection function \n",
    "def landmarksDetection(img, results, draw=False):\n",
    "    img_height, img_width= img.shape[:2]\n",
    "    # list[(x,y), (x,y)....]\n",
    "    mesh_coord = [(int(point.x * img_width), int(point.y * img_height)) for point in results.multi_face_landmarks[0].landmark]\n",
    "    if draw :\n",
    "        [cv.circle(img, p, 2, (0,255,0), -1) for p in mesh_coord]\n",
    "\n",
    "    # returning the list of tuples for each landmarks \n",
    "    return mesh_coord\n",
    "\n",
    "# Euclaidean distance \n",
    "def euclaideanDistance(point, point1):\n",
    "    x, y = point\n",
    "    x1, y1 = point1\n",
    "    distance = math.sqrt((x1 - x)**2 + (y1 - y)**2)\n",
    "    return distance\n",
    "\n",
    "# Blinking Ratio\n",
    "def blinkRatio(img, landmarks, right_indices, left_indices):\n",
    "    # Right eyes \n",
    "    # horizontal line \n",
    "    rh_right = landmarks[right_indices[0]]\n",
    "    rh_left = landmarks[right_indices[8]]\n",
    "    # vertical line \n",
    "    rv_top = landmarks[right_indices[12]]\n",
    "    rv_bottom = landmarks[right_indices[4]]\n",
    "    # draw lines on right eyes \n",
    "    # cv.line(img, rh_right, rh_left, utils.GREEN, 2)\n",
    "    # cv.line(img, rv_top, rv_bottom, utils.WHITE, 2)\n",
    "\n",
    "    # LEFT_EYE \n",
    "    # horizontal line \n",
    "    lh_right = landmarks[left_indices[0]]\n",
    "    lh_left = landmarks[left_indices[8]]\n",
    "\n",
    "    # vertical line \n",
    "    lv_top = landmarks[left_indices[12]]\n",
    "    lv_bottom = landmarks[left_indices[4]]\n",
    "\n",
    "    rhDistance = euclaideanDistance(rh_right, rh_left)\n",
    "    rvDistance = euclaideanDistance(rv_top, rv_bottom)\n",
    "\n",
    "    lvDistance = euclaideanDistance(lv_top, lv_bottom)\n",
    "    lhDistance = euclaideanDistance(lh_right, lh_left)\n",
    "\n",
    "    if rvDistance == 0 or lvDistance == 0:\n",
    "        return 0.0\n",
    "    reRatio = rhDistance/rvDistance\n",
    "    leRatio = lhDistance/lvDistance\n",
    "\n",
    "    ratio = (reRatio+leRatio)/2\n",
    "    return ratio \n",
    "\n",
    "# Eyes Extrctor function,\n",
    "def eyesExtractor(img, right_eye_coords, left_eye_coords):\n",
    "    # converting color image to  scale image \n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # getting the dimension of image \n",
    "    dim = gray.shape\n",
    "\n",
    "    # creating mask from gray scale dim\n",
    "    mask = np.zeros(dim, dtype=np.uint8)\n",
    "\n",
    "    # drawing Eyes Shape on mask with white color \n",
    "    cv.fillPoly(mask, [np.array(right_eye_coords, dtype=np.int32)], 255)\n",
    "    cv.fillPoly(mask, [np.array(left_eye_coords, dtype=np.int32)], 255)\n",
    "\n",
    "    # showing the mask \n",
    "    # cv.imshow('mask', mask)\n",
    "    \n",
    "    # draw eyes image on mask, where white shape is \n",
    "    eyes = cv.bitwise_and(gray, gray, mask=mask)\n",
    "    # change black color to gray other than eys \n",
    "    # cv.imshow('eyes draw', eyes)\n",
    "    eyes[mask==0]=155\n",
    "    \n",
    "    # getting minium and maximum x and y  for right and left eyes \n",
    "    # For Right Eye \n",
    "    r_max_x = (max(right_eye_coords, key=lambda item: item[0]))[0]\n",
    "    r_min_x = (min(right_eye_coords, key=lambda item: item[0]))[0]\n",
    "    r_max_y = (max(right_eye_coords, key=lambda item : item[1]))[1]\n",
    "    r_min_y = (min(right_eye_coords, key=lambda item: item[1]))[1]\n",
    "\n",
    "    # For LEFT Eye\n",
    "    l_max_x = (max(left_eye_coords, key=lambda item: item[0]))[0]\n",
    "    l_min_x = (min(left_eye_coords, key=lambda item: item[0]))[0]\n",
    "    l_max_y = (max(left_eye_coords, key=lambda item : item[1]))[1]\n",
    "    l_min_y = (min(left_eye_coords, key=lambda item: item[1]))[1]\n",
    "\n",
    "    # croping the eyes from mask \n",
    "    cropped_right = eyes[r_min_y: r_max_y, r_min_x: r_max_x]\n",
    "    cropped_left = eyes[l_min_y: l_max_y, l_min_x: l_max_x]\n",
    "\n",
    "    # returning the cropped eyes \n",
    "    return cropped_right, cropped_left\n",
    "\n",
    "# Eyes Postion Estimator \n",
    "def positionEstimator(cropped_eye):\n",
    "    # getting height and width of eye \n",
    "    h, w =cropped_eye.shape\n",
    "    \n",
    "    # remove the noise from images\n",
    "    gaussain_blur = cv.GaussianBlur(cropped_eye, (9,9),0)\n",
    "    median_blur = cv.medianBlur(gaussain_blur, 3)\n",
    "\n",
    "    # applying thrsholding to convert binary_image\n",
    "    ret, threshed_eye = cv.threshold(median_blur, 130, 255, cv.THRESH_BINARY)\n",
    "\n",
    "    # create fixd part for eye with \n",
    "    piece = int(w/3) \n",
    "\n",
    "    # slicing the eyes into three parts \n",
    "    right_piece = threshed_eye[0:h, 0:piece]\n",
    "    center_piece = threshed_eye[0:h, piece: piece+piece]\n",
    "    left_piece = threshed_eye[0:h, piece +piece:w]\n",
    "    \n",
    "    # calling pixel counter function\n",
    "    eye_position, color = pixelCounter(right_piece, center_piece, left_piece)\n",
    "\n",
    "    return eye_position, color \n",
    "\n",
    "# creating pixel counter function \n",
    "def pixelCounter(first_piece, second_piece, third_piece):\n",
    "    # counting black pixel in each part \n",
    "    right_part = np.sum(first_piece==0)\n",
    "    center_part = np.sum(second_piece==0)\n",
    "    left_part = np.sum(third_piece==0)\n",
    "    # creating list of these values\n",
    "    eye_parts = [right_part, center_part, left_part]\n",
    "\n",
    "    # getting the index of max values in the list \n",
    "    max_index = eye_parts.index(max(eye_parts))\n",
    "    pos_eye ='' \n",
    "    if max_index==0:\n",
    "        pos_eye=\"RIGHT\"\n",
    "        color=[utils.BLACK, utils.GREEN]\n",
    "    elif max_index==1:\n",
    "        pos_eye = 'CENTER'\n",
    "        color = [utils.YELLOW, utils.PINK]\n",
    "    elif max_index ==2:\n",
    "        pos_eye = 'LEFT'\n",
    "        color = [utils.GRAY, utils.YELLOW]\n",
    "    else:\n",
    "        pos_eye=\"Closed\"\n",
    "        color = [utils.GRAY, utils.YELLOW]\n",
    "    return pos_eye, color\n",
    "\n",
    "def main(video_path):\n",
    "    global frame_counter, CEF_COUNTER, TOTAL_BLINKS, looked_left_count, looked_right_count, looked_center_count\n",
    "    #camera = cv.VideoCapture(video_path)\n",
    "    try:\n",
    "        camera = cv.VideoCapture(video_path)\n",
    "        if not camera.isOpened():\n",
    "            raise FileNotFoundError(f\"Error: Unable to open video file at '{video_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "    with map_face_mesh.FaceMesh(refine_landmarks = True, min_detection_confidence =0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "    \n",
    "        # starting time here \n",
    "        start_time = time.time()\n",
    "        # starting Video loop here.\n",
    "        while True:\n",
    "            frame_counter +=1 # frame counter\n",
    "            ret, frame = camera.read() # getting frame from camera \n",
    "            if not ret: \n",
    "                break # no more frames break\n",
    "            #  resizing frame\n",
    "            \n",
    "            frame = cv.resize(frame, None, fx=1.5, fy=1.5, interpolation=cv.INTER_CUBIC)\n",
    "            frame_height, frame_width= frame.shape[:2]\n",
    "            rgb_frame = cv.cvtColor(frame, cv.COLOR_RGB2BGR)\n",
    "            results  = face_mesh.process(rgb_frame)\n",
    "            if results.multi_face_landmarks:\n",
    "                mesh_coords = landmarksDetection(frame, results, False)\n",
    "                ratio = blinkRatio(frame, mesh_coords, RIGHT_EYE, LEFT_EYE)\n",
    "                # cv.putText(frame, f'ratio {ratio}', (100, 100), FONTS, 1.0, utils.GREEN, 2)\n",
    "                utils.colorBackgroundText(frame,  f'Ratio : {round(ratio,2)}', FONTS, 0.7, (30,100),2, utils.PINK, utils.YELLOW)\n",
    "    \n",
    "                if ratio >5.5:\n",
    "                    CEF_COUNTER +=1\n",
    "                    # cv.putText(frame, 'Blink', (200, 50), FONTS, 1.3, utils.PINK, 2)\n",
    "                    utils.colorBackgroundText(frame,  f'Blink', FONTS, 1.7, (int(frame_height/2), 100), 2, utils.YELLOW, pad_x=6, pad_y=6, )\n",
    "    \n",
    "                else:\n",
    "                    if CEF_COUNTER>CLOSED_EYES_FRAME:\n",
    "                        TOTAL_BLINKS +=1\n",
    "                        CEF_COUNTER =0\n",
    "                # cv.putText(frame, f'Total Blinks: {TOTAL_BLINKS}', (100, 150), FONTS, 0.6, utils.GREEN, 2)\n",
    "                utils.colorBackgroundText(frame,  f'Total Blinks: {TOTAL_BLINKS}', FONTS, 0.7, (30,150),2)\n",
    "                \n",
    "                cv.polylines(frame,  [np.array([mesh_coords[p] for p in LEFT_EYE ], dtype=np.int32)], True, utils.GREEN, 1, cv.LINE_AA)\n",
    "                cv.polylines(frame,  [np.array([mesh_coords[p] for p in RIGHT_EYE ], dtype=np.int32)], True, utils.GREEN, 1, cv.LINE_AA)\n",
    "    \n",
    "                # Blink Detector Counter Completed\n",
    "                right_coords = [mesh_coords[p] for p in RIGHT_EYE]\n",
    "                left_coords = [mesh_coords[p] for p in LEFT_EYE]\n",
    "                crop_right, crop_left = eyesExtractor(frame, right_coords, left_coords)\n",
    "                # cv.imshow('right', crop_right)\n",
    "                # cv.imshow('left', crop_left)\n",
    "                eye_position, color = positionEstimator(crop_right)\n",
    "                utils.colorBackgroundText(frame, f'R: {eye_position}', FONTS, 1.0, (40, 220), 2, color[0], color[1], 8, 8)\n",
    "                eye_position_left, color = positionEstimator(crop_left)\n",
    "                utils.colorBackgroundText(frame, f'L: {eye_position_left}', FONTS, 1.0, (40, 320), 2, color[0], color[1], 8, 8)\n",
    "    \n",
    "                if eye_position == 'LEFT' or eye_position_left == 'LEFT':\n",
    "                    # Increment the count for looking left with both eyes\n",
    "                    looked_left_count += 1\n",
    "                elif eye_position == 'RIGHT' or eye_position_left == 'RIGHT':\n",
    "                    # Increment the count for looking right with both eyes\n",
    "                    looked_right_count += 1\n",
    "                elif eye_position == 'CENTER' or eye_position_left == 'CENTER':\n",
    "                    looked_center_count += 1\n",
    "                \n",
    "    \n",
    "    \n",
    "            # calculating  frame per seconds FPS\n",
    "            end_time = time.time()-start_time\n",
    "            fps = frame_counter/end_time\n",
    "    \n",
    "            frame =utils.textWithBackground(frame,f'FPS: {round(fps,1)}',FONTS, 1.0, (30, 50), bgOpacity=0.9, textThickness=2)\n",
    "            # if frame_counter == 1:\n",
    "            #     final_results_df['FPS'] = fps \n",
    "            average_fps = frame_counter / end_time\n",
    "            final_results_df['FPS'] = average_fps\n",
    "            #results_df.loc[frame_counter] = [TOTAL_BLINKS, looked_left_count, looked_right_count]\n",
    "            #results_df.loc[frame_counter] = [TOTAL_BLINKS, looked_left_count, looked_right_count]\n",
    "            #results_df.loc[frame_counter] = [TOTAL_BLINKS, looked_left_count, looked_right_count]\n",
    "\n",
    "    \n",
    "    \n",
    "#             writing image for thumbnail drawing shape\n",
    "            cv.imwrite(f'img/frame_{frame_counter}.png', frame)\n",
    "            cv.imshow('frame', frame)\n",
    "            key = cv.waitKey(2)\n",
    "            if key==ord('q') or key ==ord('Q'):\n",
    "                break\n",
    "    \n",
    "        final_results_df.loc[0] = [frame_counter, average_fps, TOTAL_BLINKS, looked_left_count, looked_right_count, looked_center_count]\n",
    "        #final_results_df.to_csv('final_results.csv', index=False)\n",
    "        total_frames = frame_counter\n",
    "        final_results_df['Percentage Looked Left'] = (final_results_df['Total Looked Left'] / total_frames) * 100\n",
    "        final_results_df['Percentage Looked Right'] = (final_results_df['Total Looked Right'] / total_frames) * 100\n",
    "        final_results_df['Percentage Looked Center'] = (final_results_df['Total Looked Center'] / total_frames) * 100\n",
    "        final_results_df['Percentage Blinks'] = (final_results_df['Total Blinks'] / total_frames) * 100\n",
    "\n",
    "        \n",
    "        #print(final_results_df)\n",
    "        #\n",
    "        #print(results_df)\n",
    "        cv.destroyAllWindows()\n",
    "        camera.release()\n",
    "        return (final_results_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     video_path = 'C:/Users/DIACTO/Videos/Captures/2-3 min introduction video.mp4'  # Replace with the desired video file path\n",
    "    video_path = 'C:/Users/Vaishnavi/Downloads/5442623-hd_1280_720_25fps.mp4'\n",
    "    final_results = main(video_path)\n",
    "\n",
    "    if final_results is not None:\n",
    "        print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8d14381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaishnavi\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ae66e9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _framework_bindings: A dynamic link library (DLL) initialization routine failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcv\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mediapipe\\__init__.py:15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 - 2022 The MediaPipe Authors.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolutions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msolutions\u001b[39;00m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtasks\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\mediapipe\\python\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020-2021 The MediaPipe Authors.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"MediaPipe Python API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_framework_bindings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_ckpt_util\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_framework_bindings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resource_util\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_framework_bindings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcalculator_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CalculatorGraph\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _framework_bindings: A dynamic link library (DLL) initialization routine failed."
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "import math\n",
    "\n",
    "# Variables for tracking\n",
    "frame_counter = 0\n",
    "CEF_COUNTER = 0\n",
    "TOTAL_BLINKS = 0\n",
    "looked_left_count = 0\n",
    "looked_right_count = 0\n",
    "looked_center_count = 0\n",
    "\n",
    "# Constants\n",
    "CLOSED_EYES_FRAME = 3\n",
    "FONTS = cv.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "# Define indices for facial landmarks\n",
    "FACE_OVAL = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109]\n",
    "LIPS = [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95, 185, 40, 39, 37, 0, 267, 269, 270, 409, 415, 310, 311, 312, 13, 82, 81, 42, 183, 78]\n",
    "LOWER_LIPS = [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "UPPER_LIPS = [185, 40, 39, 37, 0, 267, 269, 270, 409, 415, 310, 311, 312, 13, 82, 81, 42, 183, 78]\n",
    "LEFT_EYE = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]\n",
    "RIGHT_EYE = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246]\n",
    "\n",
    "map_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Main function to process video for eye tracking and blinking\n",
    "def main(video_path):\n",
    "    global frame_counter, CEF_COUNTER, TOTAL_BLINKS, looked_left_count, looked_right_count, looked_center_count\n",
    "    try:\n",
    "        camera = cv.VideoCapture(video_path)\n",
    "        if not camera.isOpened():\n",
    "            raise FileNotFoundError(f\"Error: Unable to open video file at '{video_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "    with map_face_mesh.FaceMesh(refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            frame_counter += 1\n",
    "            ret, frame = camera.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv.resize(frame, None, fx=1.5, fy=1.5, interpolation=cv.INTER_CUBIC)\n",
    "            frame_height, frame_width = frame.shape[:2]\n",
    "            rgb_frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "            results = face_mesh.process(rgb_frame)\n",
    "\n",
    "            if results.multi_face_landmarks:\n",
    "                mesh_coords = landmarksDetection(frame, results)\n",
    "                ratio = blinkRatio(frame, mesh_coords, RIGHT_EYE, LEFT_EYE)\n",
    "                utils.colorBackgroundText(frame, f'Ratio: {round(ratio, 2)}', FONTS, 0.7, (30, 100), 2, utils.PINK, utils.YELLOW)\n",
    "\n",
    "                if ratio > 5.5:\n",
    "                    CEF_COUNTER += 1\n",
    "                    utils.colorBackgroundText(frame, 'Blink', FONTS, 1.7, (int(frame_height / 2), 100), 2, utils.YELLOW, pad_x=6, pad_y=6)\n",
    "                else:\n",
    "                    if CEF_COUNTER > CLOSED_EYES_FRAME:\n",
    "                        TOTAL_BLINKS += 1\n",
    "                        CEF_COUNTER = 0\n",
    "                utils.colorBackgroundText(frame, f'Total Blinks: {TOTAL_BLINKS}', FONTS, 0.7, (30, 150), 2)\n",
    "                \n",
    "                right_coords = [mesh_coords[p] for p in RIGHT_EYE]\n",
    "                left_coords = [mesh_coords[p] for p in LEFT_EYE]\n",
    "                crop_right, crop_left = eyesExtractor(frame, right_coords, left_coords)\n",
    "                eye_position, color = positionEstimator(crop_right)\n",
    "                utils.colorBackgroundText(frame, f'R: {eye_position}', FONTS, 1.0, (40, 100), 2, color[0], color[1])\n",
    "\n",
    "            end_time = time.time() - start_time\n",
    "            fps = frame_counter / end_time\n",
    "            cv.imshow('Eye Tracker', frame)\n",
    "\n",
    "            if cv.waitKey(2) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        camera.release()\n",
    "        cv.destroyAllWindows()\n",
    "\n",
    "def landmarksDetection(img, results, draw=False):\n",
    "    img_height, img_width = img.shape[:2]\n",
    "    mesh_coords = [(int(point.x * img_width), int(point.y * img_height)) for point in results.multi_face_landmarks[0].landmark]\n",
    "    if draw:\n",
    "        [cv.circle(img, p, 2, (0, 255, 0), -1) for p in mesh_coords]\n",
    "    return mesh_coords\n",
    "\n",
    "def blinkRatio(img, landmarks, right_indices, left_indices):\n",
    "    rh_right, rh_left = landmarks[right_indices[0]], landmarks[right_indices[8]]\n",
    "    rv_top, rv_bottom = landmarks[right_indices[12]], landmarks[right_indices[4]]\n",
    "    lh_right, lh_left = landmarks[left_indices[0]], landmarks[left_indices[8]]\n",
    "    lv_top, lv_bottom = landmarks[left_indices[12]], landmarks[left_indices[4]]\n",
    "    \n",
    "    rhDistance = euclideanDistance(rh_right, rh_left)\n",
    "    rvDistance = euclideanDistance(rv_top, rv_bottom)\n",
    "    lhDistance = euclideanDistance(lh_right, lh_left)\n",
    "    lvDistance = euclideanDistance(lv_top, lv_bottom)\n",
    "    \n",
    "    if rvDistance == 0 or lvDistance == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    reRatio = rhDistance / rvDistance\n",
    "    leRatio = lhDistance / lvDistance\n",
    "    return (reRatio + leRatio) / 2\n",
    "\n",
    "def euclideanDistance(point, point1):\n",
    "    return math.sqrt((point1[0] - point[0]) ** 2 + (point1[1] - point[1]) ** 2)\n",
    "\n",
    "def eyesExtractor(img, right_eye_coords, left_eye_coords):\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    mask = np.zeros(gray.shape, dtype=np.uint8)\n",
    "    cv.fillPoly(mask, [np.array(right_eye_coords, dtype=np.int32)], 255)\n",
    "    cv.fillPoly(mask, [np.array(left_eye_coords, dtype=np.int32)], 255)\n",
    "    eyes = cv.bitwise_and(gray, gray, mask=mask)\n",
    "    eyes[mask == 0] = 155\n",
    "\n",
    "    r_max_x, r_min_x = max(right_eye_coords, key=lambda item: item[0])[0], min(right_eye_coords, key=lambda item: item[0])[0]\n",
    "    r_max_y, r_min_y = max(right_eye_coords, key=lambda item: item[1])[1], min(right_eye_coords, key=lambda item: item[1])[1]\n",
    "    l_max_x, l_min_x = max(left_eye_coords, key=lambda item: item[0])[0], min(left_eye_coords, key=lambda item: item[0])[0]\n",
    "    l_max_y, l_min_y = max(left_eye_coords, key=lambda item: item[1])[1], min(left_eye_coords, key=lambda item: item[1])[1]\n",
    "\n",
    "    cropped_right = eyes[r_min_y:r_max_y, r_min_x:r_max_x]\n",
    "    cropped_left = eyes[l_min_y:l_max_y, l_min_x:l_max_x]\n",
    "    return cropped_right, cropped_left\n",
    "\n",
    "def positionEstimator(cropped_eye):\n",
    "    h, w = cropped_eye.shape\n",
    "    gaussain_blur = cv.GaussianBlur(cropped_eye, (9, 9), 0)\n",
    "    median_blur = cv.medianBlur(gaussain_blur, 3)\n",
    "    ret, threshed_eye = cv.threshold(median_blur, 130, 255, cv.THRESH_BINARY)\n",
    "\n",
    "    piece = int(w / 3)\n",
    "    right_piece = threshed_eye[0:h, 0:piece]\n",
    "    center_piece = threshed_eye[0:h, piece:piece * 2]\n",
    "    left_piece = threshed_eye[0:h, piece * 2:w]\n",
    "\n",
    "    right_part, center_part, left_part = np.sum(right_piece == 0), np.sum(center_piece == 0), np.sum(left_piece == 0)\n",
    "    eye_position, color = \"\", (utils.WHITE, utils.BLACK)\n",
    "    if left_part < center_part and left_part < right_part:\n",
    "        eye_position, color = \"RIGHT\", (utils.BLACK, utils.YELLOW)\n",
    "    elif center_part < left_part and center_part < right_part:\n",
    "        eye_position, color = \"CENTER\", (utils.YELLOW, utils.PINK)\n",
    "    elif right_part < center_part and right_part < left_part:\n",
    "        eye_position, color = \"LEFT\", (utils.PINK, utils.WHITE)\n",
    "    return eye_position, color\n",
    "\n",
    "# Run the main function with the path to the video file\n",
    "main('C:/Users/Vaishnavi/Downloads/5442623-hd_1280_720_25fps.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84263cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
